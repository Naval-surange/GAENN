{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as md\n",
    "from ase import Atoms\n",
    "import nglview as nv\n",
    "import networkx as nx\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, SAGPooling, InnerProductDecoder\n",
    "import torch_geometric.data as data\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames = md.load_xtc(\"../simulation/para_melt.xtc\", top=\"../simulation/para_melt.gro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frames = all_frames[::100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = all_frames.xyz.shape[0]\n",
    "n_atoms = all_frames.topology.residue(0).n_atoms\n",
    "n_mols = all_frames.topology.n_residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createGraph(all_frames):\n",
    "    all_frames_fatures = []\n",
    "\n",
    "    print(\"Creating Feature matrix\")\n",
    "    for i in tqdm(range(all_frames.xyz.shape[0])):\n",
    "        mol_com_pos = []\n",
    "\n",
    "        for res in all_frames.top.residues:\n",
    "            # print(res.index,end=\" \")\n",
    "            pos = []\n",
    "            for atom in res.atoms:\n",
    "                # print(atom.index,\"-->\" , frame.xyz[0][atom.index],end=\" \")\n",
    "                pos.append(all_frames.xyz[i][atom.index])\n",
    "            mol_com_pos.append(np.mean(pos,axis=0))\n",
    "            \n",
    "            # print()\n",
    "        mol_com_pos = np.array(mol_com_pos).astype(np.float32)  \n",
    "        all_frames_fatures.append(mol_com_pos)\n",
    "\n",
    "    all_frames_fatures = np.array(all_frames_fatures).astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "    cutoff = 0.8\n",
    "\n",
    "    print(\"Creating Edge list\")\n",
    "    all_edge_list = []\n",
    "    with open(\"edge_list.txt\",\"w\") as f:\n",
    "        for frame_i in tqdm(range(n_frames)):\n",
    "            from_list = []\n",
    "            to_list = []\n",
    "\n",
    "            for i in range(len(all_frames_fatures[frame_i])):\n",
    "                for j in range(i+1,len(all_frames_fatures[frame_i])):\n",
    "                    if np.linalg.norm(all_frames_fatures[frame_i][i]-all_frames_fatures[frame_i][j]) < cutoff:\n",
    "                        f.write(str(i)+\" \"+str(j)+\" \"+str(np.linalg.norm(all_frames_fatures[frame_i][i]-all_frames_fatures[frame_i][j]))+\"\\n\")\n",
    "                        from_list.append(i)\n",
    "                        to_list.append(j)\n",
    "\n",
    "                        to_list.append(i)\n",
    "                        from_list.append(j)\n",
    "\n",
    "            edge_list = np.array([from_list,to_list]).astype(np.int64)\n",
    "            all_edge_list.append(edge_list)\n",
    "    print(\"creating Graphs\")\n",
    "    graphs = []\n",
    "    for frame in tqdm(range(n_frames)):\n",
    "        g = data.Data(x=torch.tensor(all_frames_fatures[frame]).float(), edge_index=torch.tensor(all_edge_list[frame]).long(), y=torch.tensor([0]))\n",
    "        graphs.append(g)\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Feature matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 25.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Edge list\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [02:07<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating Graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 6991.65it/s]\n"
     ]
    }
   ],
   "source": [
    "graphs = createGraph(all_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_adj(edge_index, num_nodes=None):\n",
    "    if num_nodes is None:\n",
    "        num_nodes = edge_index.max() + 1\n",
    "    adj = torch.zeros(num_nodes, num_nodes)\n",
    "    adj[edge_index[0], edge_index[1]] = 1\n",
    "    return adj\n",
    "\n",
    "def convert_to_edge_index(adj):\n",
    "    edge_index = adj.nonzero().t()\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "\n",
    "# g1 = graphs[0]\n",
    "# nx_g1 = to_networkx(g1)\n",
    "# pos = nx.draw_spring(nx_g1, with_labels=False, node_size=50)\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "EPS = 1e-15\n",
    "MAX_LOGSTD = 10\n",
    "edgeShape = None\n",
    "featureShape = None\n",
    "\n",
    "\n",
    "class InnerProductDecoder(torch.nn.Module):\n",
    "    r\"\"\"The inner product decoder from the `\"Variational Graph Auto-Encoders\"\n",
    "    <https://arxiv.org/abs/1611.07308>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\sigma(\\mathbf{Z}\\mathbf{Z}^{\\top})\n",
    "\n",
    "    where :math:`\\mathbf{Z} \\in \\mathbb{R}^{N \\times d}` denotes the latent\n",
    "    space produced by the encoder.\"\"\"\n",
    "\n",
    "    def forward(self, z: Tensor, edge_index: Tensor,\n",
    "                sigmoid: bool = True) -> Tensor:\n",
    "        r\"\"\"Decodes the latent variables :obj:`z` into edge probabilities for\n",
    "        the given node-pairs :obj:`edge_index`.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            sigmoid (bool, optional): If set to :obj:`False`, does not apply\n",
    "                the logistic sigmoid function to the output.\n",
    "                (default: :obj:`True`)\n",
    "        \"\"\"\n",
    "        value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=1)\n",
    "        return torch.sigmoid(value) if sigmoid else value\n",
    "\n",
    "    def forward_all(self, z: Tensor, sigmoid: bool = True) -> Tensor:\n",
    "        r\"\"\"Decodes the latent variables :obj:`z` into a probabilistic dense\n",
    "        adjacency matrix.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            sigmoid (bool, optional): If set to :obj:`False`, does not apply\n",
    "                the logistic sigmoid function to the output.\n",
    "                (default: :obj:`True`)\n",
    "        \"\"\"\n",
    "        adj = torch.matmul(z, z.t())\n",
    "        return torch.sigmoid(adj) if sigmoid else adj\n",
    "\n",
    "\n",
    "class GAE(torch.nn.Module):\n",
    "    r\"\"\"The Graph Auto-Encoder model from the\n",
    "    `\"Variational Graph Auto-Encoders\" <https://arxiv.org/abs/1611.07308>`_\n",
    "    paper based on user-defined encoder and decoder models.\n",
    "\n",
    "    Args:\n",
    "        encoder (torch.nn.Module): The encoder module.\n",
    "        decoder (torch.nn.Module, optional): The decoder module. If set to\n",
    "            :obj:`None`, will default to the\n",
    "            :class:`torch_geometric.nn.models.InnerProductDecoder`.\n",
    "            (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder: Module, decoder: Optional[Module] = None):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = InnerProductDecoder() if decoder is None else decoder\n",
    "        GAE.reset_parameters(self)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n",
    "        reset(self.encoder)\n",
    "        reset(self.decoder)\n",
    "\n",
    "    def forward(self, *args, **kwargs) -> Tensor:  # pragma: no cover\n",
    "        r\"\"\"Alias for :meth:`encode`.\"\"\"\n",
    "        return self.encoder(*args, **kwargs)\n",
    "\n",
    "    def encode(self, *args, **kwargs) -> Tensor:\n",
    "        r\"\"\"Runs the encoder and computes node-wise latent variables.\"\"\"\n",
    "        return self.encoder(*args, **kwargs)\n",
    "\n",
    "    def decode(self, *args, **kwargs) -> Tensor:\n",
    "        r\"\"\"Runs the decoder and computes edge probabilities.\"\"\"\n",
    "        return self.decoder(*args, **kwargs)\n",
    "\n",
    "    def recon_loss(self, z: Tensor, pos_edge_index: Tensor,\n",
    "                   neg_edge_index: Optional[Tensor] = None) -> Tensor:\n",
    "        r\"\"\"Given latent variables :obj:`z`, computes the binary cross\n",
    "        entropy loss for positive edges :obj:`pos_edge_index` and negative\n",
    "        sampled edges.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            pos_edge_index (torch.Tensor): The positive edges to train against.\n",
    "            neg_edge_index (torch.Tensor, optional): The negative edges to\n",
    "                train against. If not given, uses negative sampling to\n",
    "                calculate negative edges. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        pos_loss = -torch.log(\n",
    "            self.decoder(z, pos_edge_index, sigmoid=True)[0] + EPS).mean()\n",
    "\n",
    "        if neg_edge_index is None:\n",
    "            neg_edge_index = negative_sampling(pos_edge_index, z.size(0))\n",
    "        neg_loss = -torch.log(1 -\n",
    "                              self.decoder(z, neg_edge_index.long(), sigmoid=True)[0] +\n",
    "                              EPS).mean()\n",
    "\n",
    "        return pos_loss + neg_loss\n",
    "\n",
    "    def test(self, z: Tensor, pos_edge_index: Tensor,\n",
    "             neg_edge_index: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        r\"\"\"Given latent variables :obj:`z`, positive edges\n",
    "        :obj:`pos_edge_index` and negative edges :obj:`neg_edge_index`,\n",
    "        computes area under the ROC curve (AUC) and average precision (AP)\n",
    "        \n",
    "        scores.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            pos_edge_index (torch.Tensor): The positive edges to evaluate\n",
    "                against.\n",
    "            neg_edge_index (torch.Tensor): The negative edges to evaluate\n",
    "                against.\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "        pos_y = z.new_ones(pos_edge_index.size(1))\n",
    "        neg_y = z.new_zeros(neg_edge_index.size(1))\n",
    "        y = torch.cat([pos_y, neg_y], dim=0)\n",
    "\n",
    "        pos_pred = self.decoder(z, pos_edge_index, sigmoid=True)\n",
    "        neg_pred = self.decoder(z, neg_edge_index, sigmoid=True)\n",
    "        pred = torch.cat([pos_pred, neg_pred], dim=0)\n",
    "\n",
    "        y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()\n",
    "\n",
    "        return roc_auc_score(y, pred), average_precision_score(y, pred)\n",
    "\n",
    "\n",
    "class VGAE(GAE):\n",
    "    r\"\"\"The Variational Graph Auto-Encoder model from the\n",
    "    `\"Variational Graph Auto-Encoders\" <https://arxiv.org/abs/1611.07308>`_\n",
    "    paper.\n",
    "\n",
    "    Args:\n",
    "        encoder (torch.nn.Module): The encoder module to compute :math:`\\mu`\n",
    "            and :math:`\\log\\sigma^2`.\n",
    "        decoder (torch.nn.Module, optional): The decoder module. If set to\n",
    "            :obj:`None`, will default to the\n",
    "            :class:`torch_geometric.nn.models.InnerProductDecoder`.\n",
    "            (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder: Module, decoder: Optional[Module] = None):\n",
    "        super().__init__(encoder, decoder)\n",
    "\n",
    "    def reparametrize(self, mu: Tensor, logstd: Tensor) -> Tensor:\n",
    "        if self.training:\n",
    "            return mu + torch.randn_like(logstd) * torch.exp(logstd)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def encode(self, *args, **kwargs) -> Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        self.__mu__, self.__logstd__, self.edge_index = self.encoder(\n",
    "            *args, **kwargs)\n",
    "        self.__logstd__ = self.__logstd__.clamp(max=MAX_LOGSTD)\n",
    "        z = self.reparametrize(self.__mu__, self.__logstd__)\n",
    "        return z, self.edge_index\n",
    "\n",
    "    def kl_loss(self, mu: Optional[Tensor] = None,\n",
    "                logstd: Optional[Tensor] = None) -> Tensor:\n",
    "        r\"\"\"Computes the KL loss, either for the passed arguments :obj:`mu`\n",
    "        and :obj:`logstd`, or based on latent variables from last encoding.\n",
    "\n",
    "        Args:\n",
    "            mu (torch.Tensor, optional): The latent space for :math:`\\mu`. If\n",
    "                set to :obj:`None`, uses the last computation of :math:`\\mu`.\n",
    "                (default: :obj:`None`)\n",
    "            logstd (torch.Tensor, optional): The latent space for\n",
    "                :math:`\\log\\sigma`.  If set to :obj:`None`, uses the last\n",
    "                computation of :math:`\\log\\sigma^2`. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        mu = self.__mu__ if mu is None else mu\n",
    "        logstd = self.__logstd__ if logstd is None else logstd.clamp(\n",
    "            max=MAX_LOGSTD)\n",
    "        return -0.5 * torch.mean(\n",
    "            torch.sum(1 + 2 * logstd - mu**2 - logstd.exp()**2, dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv2 = GCNConv(2*out_channels, 1 * out_channels)\n",
    "        self.pool = SAGPooling(out_channels, 0.5)\n",
    "        self.conv_mu = GCNConv(1 * out_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(1 * out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        global edgeShape, featureShape\n",
    "        # print(\"input:\",x.shape, edge_index.shape)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.silu(x)\n",
    "        # print(\"conv1:\",x.shape, edge_index.shape)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.silu(x)\n",
    "        # print(\"conv2:\",x.shape, edge_index.shape)\n",
    "        edgeShape = edge_index.shape\n",
    "        featureShape = x.shape\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index), edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalGCNDecoder(torch.nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv2 = GCNConv(2 * out_channels, 1 * out_channels)\n",
    "    def forward(self, x, edge_index, sigmoid=True):\n",
    "        global edgeShape, featureShape\n",
    "        # print(\"input:\",x.shape, edge_index.shape)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.silu(x)\n",
    "        # print(\"conv1:\",x.shape, edge_index.shape)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.silu(x)\n",
    "        # print(\"conv2:\",x.shape, edge_index.shape)\n",
    "        return x, edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "in_channels = graphs[0].num_features\n",
    "out_channels = 2\n",
    "lr = 1e-3\n",
    "n_epochs = 500\n",
    "batch_size=2\n",
    "test_train_split = 0.8\n",
    "model_name = \"InterGVAE_para_melt_v1.pt\"\n",
    "model_loaded = False\n",
    "force_train = False\n",
    "\n",
    "if os.path.exists(\"./models/\"+model_name) and not force_train:\n",
    "    model = torch.load(\"./models/\"+model_name)\n",
    "    model_loaded = True\n",
    "else:\n",
    "    model = VGAE(VariationalGCNEncoder(in_channels, out_channels),\n",
    "                VariationalGCNDecoder(out_channels, in_channels))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=300, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(graphs[:int(n_frames*test_train_split)], batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(graphs[int(n_frames*test_train_split):], batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFxn = torch.nn.MSELoss()\n",
    "def train():\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    model.float()\n",
    "    loss_all = 0\n",
    "    feature_loss_all = 0\n",
    "    edge_loss_all = 0\n",
    "    kl_loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        z,encoded_edge_index = model.encode(data.x, data.edge_index)\n",
    "        decoded_x, decoded_edge_index = model.decode(z, encoded_edge_index)\n",
    "\n",
    "        FeatureLoss = lossFxn(decoded_x, data.x)\n",
    "        EdgeLoss = lossFxn(decoded_edge_index.float(), data.edge_index)\n",
    "        loss = FeatureLoss + EdgeLoss\n",
    "        loss = loss \n",
    "\n",
    "        loss_all +=  float(loss)\n",
    "        feature_loss_all += float(FeatureLoss)\n",
    "        edge_loss_all += float(EdgeLoss)\n",
    "        kl_loss_all += float(model.kl_loss()/data.num_nodes)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "\n",
    "    return loss_all / len(train_loader), feature_loss_all / len(train_loader), edge_loss_all / len(train_loader), kl_loss_all / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFxn = torch.nn.MSELoss()\n",
    "def test():\n",
    "    model.eval()\n",
    "    model.zero_grad()\n",
    "    model.float()\n",
    "    loss_all = 0\n",
    "    feature_loss_all = 0\n",
    "    edge_loss_all = 0\n",
    "    kl_loss_all = 0\n",
    "\n",
    "    for data in test_loader:\n",
    "        optimizer.zero_grad()\n",
    "        z,encoded_edge_index = model.encode(data.x, data.edge_index)\n",
    "        decoded_x, decoded_edge_index = model.decode(z, encoded_edge_index)\n",
    "\n",
    "        FeatureLoss = lossFxn(decoded_x, data.x)\n",
    "        EdgeLoss = lossFxn(decoded_edge_index.float(), data.edge_index)\n",
    "        loss = FeatureLoss + EdgeLoss\n",
    "        loss = loss \n",
    "\n",
    "        loss_all +=  float(loss)\n",
    "        feature_loss_all += float(FeatureLoss)\n",
    "        edge_loss_all += float(EdgeLoss)\n",
    "        kl_loss_all += float(model.kl_loss()/data.num_nodes)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    return loss_all / len(test_loader), feature_loss_all / len(test_loader), edge_loss_all / len(test_loader), kl_loss_all / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001\n",
      "\tTrain:\tTotal Loss: 14.3978, Feature Loss: 14.3978,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 10.8379, Feature Loss: 10.8379, , LR: 0.001000\n",
      "Epoch: 002\n",
      "\tTrain:\tTotal Loss: 14.1084, Feature Loss: 14.1084,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 10.5402, Feature Loss: 10.5402, , LR: 0.001000\n",
      "Epoch: 003\n",
      "\tTrain:\tTotal Loss: 13.6746, Feature Loss: 13.6746,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 10.0738, Feature Loss: 10.0738, , LR: 0.001000\n",
      "Epoch: 004\n",
      "\tTrain:\tTotal Loss: 12.9458, Feature Loss: 12.9458,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 9.3079, Feature Loss: 9.3079, , LR: 0.001000\n",
      "Epoch: 005\n",
      "\tTrain:\tTotal Loss: 11.7880, Feature Loss: 11.7880,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 8.0978, Feature Loss: 8.0978, , LR: 0.001000\n",
      "Epoch: 006\n",
      "\tTrain:\tTotal Loss: 10.1001, Feature Loss: 10.1001,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 6.6003, Feature Loss: 6.6003, , LR: 0.001000\n",
      "Epoch: 007\n",
      "\tTrain:\tTotal Loss: 8.1710, Feature Loss: 8.1710,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 4.9342, Feature Loss: 4.9342, , LR: 0.001000\n",
      "Epoch: 008\n",
      "\tTrain:\tTotal Loss: 6.1378, Feature Loss: 6.1378,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 3.5303, Feature Loss: 3.5303, , LR: 0.001000\n",
      "Epoch: 009\n",
      "\tTrain:\tTotal Loss: 4.5445, Feature Loss: 4.5445,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 2.6619, Feature Loss: 2.6619, , LR: 0.001000\n",
      "Epoch: 010\n",
      "\tTrain:\tTotal Loss: 3.6214, Feature Loss: 3.6214,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 2.2088, Feature Loss: 2.2088, , LR: 0.001000\n",
      "Epoch: 011\n",
      "\tTrain:\tTotal Loss: 3.1119, Feature Loss: 3.1119,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 2.0323, Feature Loss: 2.0323, , LR: 0.001000\n",
      "Epoch: 012\n",
      "\tTrain:\tTotal Loss: 2.8692, Feature Loss: 2.8692,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9799, Feature Loss: 1.9799, , LR: 0.001000\n",
      "Epoch: 013\n",
      "\tTrain:\tTotal Loss: 2.7643, Feature Loss: 2.7643,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9708, Feature Loss: 1.9708, , LR: 0.001000\n",
      "Epoch: 014\n",
      "\tTrain:\tTotal Loss: 2.7253, Feature Loss: 2.7253,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9785, Feature Loss: 1.9785, , LR: 0.001000\n",
      "Epoch: 015\n",
      "\tTrain:\tTotal Loss: 2.7046, Feature Loss: 2.7046,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9861, Feature Loss: 1.9861, , LR: 0.001000\n",
      "Epoch: 016\n",
      "\tTrain:\tTotal Loss: 2.6921, Feature Loss: 2.6921,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9845, Feature Loss: 1.9845, , LR: 0.001000\n",
      "Epoch: 017\n",
      "\tTrain:\tTotal Loss: 2.6873, Feature Loss: 2.6873,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9895, Feature Loss: 1.9895, , LR: 0.001000\n",
      "Epoch: 018\n",
      "\tTrain:\tTotal Loss: 2.6805, Feature Loss: 2.6805,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9881, Feature Loss: 1.9881, , LR: 0.001000\n",
      "Epoch: 019\n",
      "\tTrain:\tTotal Loss: 2.6783, Feature Loss: 2.6783,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9877, Feature Loss: 1.9877, , LR: 0.001000\n",
      "Epoch: 020\n",
      "\tTrain:\tTotal Loss: 2.6760, Feature Loss: 2.6760,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9866, Feature Loss: 1.9866, , LR: 0.001000\n",
      "Epoch: 021\n",
      "\tTrain:\tTotal Loss: 2.6712, Feature Loss: 2.6712,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9851, Feature Loss: 1.9851, , LR: 0.001000\n",
      "Epoch: 022\n",
      "\tTrain:\tTotal Loss: 2.6683, Feature Loss: 2.6683,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9861, Feature Loss: 1.9861, , LR: 0.001000\n",
      "Epoch: 023\n",
      "\tTrain:\tTotal Loss: 2.6662, Feature Loss: 2.6662,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9808, Feature Loss: 1.9808, , LR: 0.001000\n",
      "Epoch: 024\n",
      "\tTrain:\tTotal Loss: 2.6634, Feature Loss: 2.6634,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9769, Feature Loss: 1.9769, , LR: 0.001000\n",
      "Epoch: 025\n",
      "\tTrain:\tTotal Loss: 2.6612, Feature Loss: 2.6612,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9744, Feature Loss: 1.9744, , LR: 0.001000\n",
      "Epoch: 026\n",
      "\tTrain:\tTotal Loss: 2.6601, Feature Loss: 2.6601,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9749, Feature Loss: 1.9749, , LR: 0.001000\n",
      "Epoch: 027\n",
      "\tTrain:\tTotal Loss: 2.6572, Feature Loss: 2.6572,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9740, Feature Loss: 1.9740, , LR: 0.001000\n",
      "Epoch: 028\n",
      "\tTrain:\tTotal Loss: 2.6544, Feature Loss: 2.6544,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9677, Feature Loss: 1.9677, , LR: 0.001000\n",
      "Epoch: 029\n",
      "\tTrain:\tTotal Loss: 2.6521, Feature Loss: 2.6521,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9687, Feature Loss: 1.9687, , LR: 0.001000\n",
      "Epoch: 030\n",
      "\tTrain:\tTotal Loss: 2.6497, Feature Loss: 2.6497,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9664, Feature Loss: 1.9664, , LR: 0.001000\n",
      "Epoch: 031\n",
      "\tTrain:\tTotal Loss: 2.6467, Feature Loss: 2.6467,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9667, Feature Loss: 1.9667, , LR: 0.001000\n",
      "Epoch: 032\n",
      "\tTrain:\tTotal Loss: 2.6462, Feature Loss: 2.6462,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9643, Feature Loss: 1.9643, , LR: 0.001000\n",
      "Epoch: 033\n",
      "\tTrain:\tTotal Loss: 2.6441, Feature Loss: 2.6441,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9667, Feature Loss: 1.9667, , LR: 0.001000\n",
      "Epoch: 034\n",
      "\tTrain:\tTotal Loss: 2.6414, Feature Loss: 2.6414,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9592, Feature Loss: 1.9592, , LR: 0.001000\n",
      "Epoch: 035\n",
      "\tTrain:\tTotal Loss: 2.6398, Feature Loss: 2.6398,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9620, Feature Loss: 1.9620, , LR: 0.001000\n",
      "Epoch: 036\n",
      "\tTrain:\tTotal Loss: 2.6366, Feature Loss: 2.6366,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9611, Feature Loss: 1.9611, , LR: 0.001000\n",
      "Epoch: 037\n",
      "\tTrain:\tTotal Loss: 2.6345, Feature Loss: 2.6345,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9581, Feature Loss: 1.9581, , LR: 0.001000\n",
      "Epoch: 038\n",
      "\tTrain:\tTotal Loss: 2.6336, Feature Loss: 2.6336,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9575, Feature Loss: 1.9575, , LR: 0.001000\n",
      "Epoch: 039\n",
      "\tTrain:\tTotal Loss: 2.6307, Feature Loss: 2.6307,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9538, Feature Loss: 1.9538, , LR: 0.001000\n",
      "Epoch: 040\n",
      "\tTrain:\tTotal Loss: 2.6301, Feature Loss: 2.6301,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9537, Feature Loss: 1.9537, , LR: 0.001000\n",
      "Epoch: 041\n",
      "\tTrain:\tTotal Loss: 2.6276, Feature Loss: 2.6276,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9560, Feature Loss: 1.9560, , LR: 0.001000\n",
      "Epoch: 042\n",
      "\tTrain:\tTotal Loss: 2.6251, Feature Loss: 2.6251,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9541, Feature Loss: 1.9541, , LR: 0.001000\n",
      "Epoch: 043\n",
      "\tTrain:\tTotal Loss: 2.6240, Feature Loss: 2.6240,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9487, Feature Loss: 1.9487, , LR: 0.001000\n",
      "Epoch: 044\n",
      "\tTrain:\tTotal Loss: 2.6232, Feature Loss: 2.6232,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9536, Feature Loss: 1.9536, , LR: 0.001000\n",
      "Epoch: 045\n",
      "\tTrain:\tTotal Loss: 2.6203, Feature Loss: 2.6203,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9534, Feature Loss: 1.9534, , LR: 0.001000\n",
      "Epoch: 046\n",
      "\tTrain:\tTotal Loss: 2.6200, Feature Loss: 2.6200,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9536, Feature Loss: 1.9536, , LR: 0.001000\n",
      "Epoch: 047\n",
      "\tTrain:\tTotal Loss: 2.6182, Feature Loss: 2.6182,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9499, Feature Loss: 1.9499, , LR: 0.001000\n",
      "Epoch: 048\n",
      "\tTrain:\tTotal Loss: 2.6172, Feature Loss: 2.6172,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9458, Feature Loss: 1.9458, , LR: 0.001000\n",
      "Epoch: 049\n",
      "\tTrain:\tTotal Loss: 2.6158, Feature Loss: 2.6158,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9468, Feature Loss: 1.9468, , LR: 0.001000\n",
      "Epoch: 050\n",
      "\tTrain:\tTotal Loss: 2.6152, Feature Loss: 2.6152,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9501, Feature Loss: 1.9501, , LR: 0.001000\n",
      "Epoch: 051\n",
      "\tTrain:\tTotal Loss: 2.6140, Feature Loss: 2.6140,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9512, Feature Loss: 1.9512, , LR: 0.001000\n",
      "Epoch: 052\n",
      "\tTrain:\tTotal Loss: 2.6118, Feature Loss: 2.6118,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9476, Feature Loss: 1.9476, , LR: 0.001000\n",
      "Epoch: 053\n",
      "\tTrain:\tTotal Loss: 2.6112, Feature Loss: 2.6112,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9432, Feature Loss: 1.9432, , LR: 0.001000\n",
      "Epoch: 054\n",
      "\tTrain:\tTotal Loss: 2.6115, Feature Loss: 2.6115,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9451, Feature Loss: 1.9451, , LR: 0.001000\n",
      "Epoch: 055\n",
      "\tTrain:\tTotal Loss: 2.6090, Feature Loss: 2.6090,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9465, Feature Loss: 1.9465, , LR: 0.001000\n",
      "Epoch: 056\n",
      "\tTrain:\tTotal Loss: 2.6084, Feature Loss: 2.6084,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9474, Feature Loss: 1.9474, , LR: 0.001000\n",
      "Epoch: 057\n",
      "\tTrain:\tTotal Loss: 2.6069, Feature Loss: 2.6069,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9472, Feature Loss: 1.9472, , LR: 0.001000\n",
      "Epoch: 058\n",
      "\tTrain:\tTotal Loss: 2.6079, Feature Loss: 2.6079,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9405, Feature Loss: 1.9405, , LR: 0.001000\n",
      "Epoch: 059\n",
      "\tTrain:\tTotal Loss: 2.6052, Feature Loss: 2.6052,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9480, Feature Loss: 1.9480, , LR: 0.001000\n",
      "Epoch: 060\n",
      "\tTrain:\tTotal Loss: 2.6040, Feature Loss: 2.6040,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9436, Feature Loss: 1.9436, , LR: 0.001000\n",
      "Epoch: 061\n",
      "\tTrain:\tTotal Loss: 2.6028, Feature Loss: 2.6028,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9432, Feature Loss: 1.9432, , LR: 0.001000\n",
      "Epoch: 062\n",
      "\tTrain:\tTotal Loss: 2.6023, Feature Loss: 2.6023,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9446, Feature Loss: 1.9446, , LR: 0.001000\n",
      "Epoch: 063\n",
      "\tTrain:\tTotal Loss: 2.6010, Feature Loss: 2.6010,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9428, Feature Loss: 1.9428, , LR: 0.001000\n",
      "Epoch: 064\n",
      "\tTrain:\tTotal Loss: 2.6003, Feature Loss: 2.6003,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9394, Feature Loss: 1.9394, , LR: 0.001000\n",
      "Epoch: 065\n",
      "\tTrain:\tTotal Loss: 2.5988, Feature Loss: 2.5988,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9444, Feature Loss: 1.9444, , LR: 0.001000\n",
      "Epoch: 066\n",
      "\tTrain:\tTotal Loss: 2.5969, Feature Loss: 2.5969,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9364, Feature Loss: 1.9364, , LR: 0.001000\n",
      "Epoch: 067\n",
      "\tTrain:\tTotal Loss: 2.5944, Feature Loss: 2.5944,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9404, Feature Loss: 1.9404, , LR: 0.001000\n",
      "Epoch: 068\n",
      "\tTrain:\tTotal Loss: 2.5927, Feature Loss: 2.5927,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9387, Feature Loss: 1.9387, , LR: 0.001000\n",
      "Epoch: 069\n",
      "\tTrain:\tTotal Loss: 2.5885, Feature Loss: 2.5885,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9356, Feature Loss: 1.9356, , LR: 0.001000\n",
      "Epoch: 070\n",
      "\tTrain:\tTotal Loss: 2.5836, Feature Loss: 2.5836,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9360, Feature Loss: 1.9360, , LR: 0.001000\n",
      "Epoch: 071\n",
      "\tTrain:\tTotal Loss: 2.5774, Feature Loss: 2.5774,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9285, Feature Loss: 1.9285, , LR: 0.001000\n",
      "Epoch: 072\n",
      "\tTrain:\tTotal Loss: 2.5697, Feature Loss: 2.5697,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9263, Feature Loss: 1.9263, , LR: 0.001000\n",
      "Epoch: 073\n",
      "\tTrain:\tTotal Loss: 2.5585, Feature Loss: 2.5585,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9237, Feature Loss: 1.9237, , LR: 0.001000\n",
      "Epoch: 074\n",
      "\tTrain:\tTotal Loss: 2.5454, Feature Loss: 2.5454,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9109, Feature Loss: 1.9109, , LR: 0.001000\n",
      "Epoch: 075\n",
      "\tTrain:\tTotal Loss: 2.5312, Feature Loss: 2.5312,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.9072, Feature Loss: 1.9072, , LR: 0.001000\n",
      "Epoch: 076\n",
      "\tTrain:\tTotal Loss: 2.5150, Feature Loss: 2.5150,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.8929, Feature Loss: 1.8929, , LR: 0.001000\n",
      "Epoch: 077\n",
      "\tTrain:\tTotal Loss: 2.4969, Feature Loss: 2.4969,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.8839, Feature Loss: 1.8839, , LR: 0.001000\n",
      "Epoch: 078\n",
      "\tTrain:\tTotal Loss: 2.4791, Feature Loss: 2.4791,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.8693, Feature Loss: 1.8693, , LR: 0.001000\n",
      "Epoch: 079\n",
      "\tTrain:\tTotal Loss: 2.4587, Feature Loss: 2.4587,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.8573, Feature Loss: 1.8573, , LR: 0.001000\n",
      "Epoch: 080\n",
      "\tTrain:\tTotal Loss: 2.4372, Feature Loss: 2.4372,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.8407, Feature Loss: 1.8407, , LR: 0.001000\n",
      "Epoch: 081\n",
      "\tTrain:\tTotal Loss: 2.4149, Feature Loss: 2.4149,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.8277, Feature Loss: 1.8277, , LR: 0.001000\n",
      "Epoch: 082\n",
      "\tTrain:\tTotal Loss: 2.3921, Feature Loss: 2.3921,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.8116, Feature Loss: 1.8116, , LR: 0.001000\n",
      "Epoch: 083\n",
      "\tTrain:\tTotal Loss: 2.3697, Feature Loss: 2.3697,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.7978, Feature Loss: 1.7978, , LR: 0.001000\n",
      "Epoch: 084\n",
      "\tTrain:\tTotal Loss: 2.3449, Feature Loss: 2.3449,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.7798, Feature Loss: 1.7798, , LR: 0.001000\n",
      "Epoch: 085\n",
      "\tTrain:\tTotal Loss: 2.3161, Feature Loss: 2.3161,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.7623, Feature Loss: 1.7623, , LR: 0.001000\n",
      "Epoch: 086\n",
      "\tTrain:\tTotal Loss: 2.2892, Feature Loss: 2.2892,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.7418, Feature Loss: 1.7418, , LR: 0.001000\n",
      "Epoch: 087\n",
      "\tTrain:\tTotal Loss: 2.2614, Feature Loss: 2.2614,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.7249, Feature Loss: 1.7249, , LR: 0.001000\n",
      "Epoch: 088\n",
      "\tTrain:\tTotal Loss: 2.2306, Feature Loss: 2.2306,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.7005, Feature Loss: 1.7005, , LR: 0.001000\n",
      "Epoch: 089\n",
      "\tTrain:\tTotal Loss: 2.1991, Feature Loss: 2.1991,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.6739, Feature Loss: 1.6739, , LR: 0.001000\n",
      "Epoch: 090\n",
      "\tTrain:\tTotal Loss: 2.1668, Feature Loss: 2.1668,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.6555, Feature Loss: 1.6555, , LR: 0.001000\n",
      "Epoch: 091\n",
      "\tTrain:\tTotal Loss: 2.1268, Feature Loss: 2.1268,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.6243, Feature Loss: 1.6243, , LR: 0.001000\n",
      "Epoch: 092\n",
      "\tTrain:\tTotal Loss: 2.0895, Feature Loss: 2.0895,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.5991, Feature Loss: 1.5991, , LR: 0.001000\n",
      "Epoch: 093\n",
      "\tTrain:\tTotal Loss: 2.0518, Feature Loss: 2.0518,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.5693, Feature Loss: 1.5693, , LR: 0.001000\n",
      "Epoch: 094\n",
      "\tTrain:\tTotal Loss: 2.0109, Feature Loss: 2.0109,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.5396, Feature Loss: 1.5396, , LR: 0.001000\n",
      "Epoch: 095\n",
      "\tTrain:\tTotal Loss: 1.9699, Feature Loss: 1.9699,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.5084, Feature Loss: 1.5084, , LR: 0.001000\n",
      "Epoch: 096\n",
      "\tTrain:\tTotal Loss: 1.9281, Feature Loss: 1.9281,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.4764, Feature Loss: 1.4764, , LR: 0.001000\n",
      "Epoch: 097\n",
      "\tTrain:\tTotal Loss: 1.8845, Feature Loss: 1.8845,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.4540, Feature Loss: 1.4540, , LR: 0.001000\n",
      "Epoch: 098\n",
      "\tTrain:\tTotal Loss: 1.8424, Feature Loss: 1.8424,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.4158, Feature Loss: 1.4158, , LR: 0.001000\n",
      "Epoch: 099\n",
      "\tTrain:\tTotal Loss: 1.8097, Feature Loss: 1.8097,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.3797, Feature Loss: 1.3797, , LR: 0.001000\n",
      "Epoch: 100\n",
      "\tTrain:\tTotal Loss: 1.7629, Feature Loss: 1.7629,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.3629, Feature Loss: 1.3629, , LR: 0.001000\n",
      "Epoch: 101\n",
      "\tTrain:\tTotal Loss: 1.7259, Feature Loss: 1.7259,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.3314, Feature Loss: 1.3314, , LR: 0.001000\n",
      "Epoch: 102\n",
      "\tTrain:\tTotal Loss: 1.6906, Feature Loss: 1.6906,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.2950, Feature Loss: 1.2950, , LR: 0.001000\n",
      "Epoch: 103\n",
      "\tTrain:\tTotal Loss: 1.6609, Feature Loss: 1.6609,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.2817, Feature Loss: 1.2817, , LR: 0.001000\n",
      "Epoch: 104\n",
      "\tTrain:\tTotal Loss: 1.6207, Feature Loss: 1.6207,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.2543, Feature Loss: 1.2543, , LR: 0.001000\n",
      "Epoch: 105\n",
      "\tTrain:\tTotal Loss: 1.5926, Feature Loss: 1.5926,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.2333, Feature Loss: 1.2333, , LR: 0.001000\n",
      "Epoch: 106\n",
      "\tTrain:\tTotal Loss: 1.5623, Feature Loss: 1.5623,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.2181, Feature Loss: 1.2181, , LR: 0.001000\n",
      "Epoch: 107\n",
      "\tTrain:\tTotal Loss: 1.5376, Feature Loss: 1.5376,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.2027, Feature Loss: 1.2027, , LR: 0.001000\n",
      "Epoch: 108\n",
      "\tTrain:\tTotal Loss: 1.5175, Feature Loss: 1.5175,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.1804, Feature Loss: 1.1804, , LR: 0.001000\n",
      "Epoch: 109\n",
      "\tTrain:\tTotal Loss: 1.4978, Feature Loss: 1.4978,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.1664, Feature Loss: 1.1664, , LR: 0.001000\n",
      "Epoch: 110\n",
      "\tTrain:\tTotal Loss: 1.4757, Feature Loss: 1.4757,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.1600, Feature Loss: 1.1600, , LR: 0.001000\n",
      "Epoch: 111\n",
      "\tTrain:\tTotal Loss: 1.4600, Feature Loss: 1.4600,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.1491, Feature Loss: 1.1491, , LR: 0.001000\n",
      "Epoch: 112\n",
      "\tTrain:\tTotal Loss: 1.4437, Feature Loss: 1.4437,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.1394, Feature Loss: 1.1394, , LR: 0.001000\n",
      "Epoch: 113\n",
      "\tTrain:\tTotal Loss: 1.4296, Feature Loss: 1.4296,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.1229, Feature Loss: 1.1229, , LR: 0.001000\n",
      "Epoch: 114\n",
      "\tTrain:\tTotal Loss: 1.4202, Feature Loss: 1.4202,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.1251, Feature Loss: 1.1251, , LR: 0.001000\n",
      "Epoch: 115\n",
      "\tTrain:\tTotal Loss: 1.4089, Feature Loss: 1.4089,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.1154, Feature Loss: 1.1154, , LR: 0.001000\n",
      "Epoch: 116\n",
      "\tTrain:\tTotal Loss: 1.3997, Feature Loss: 1.3997,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.1164, Feature Loss: 1.1164, , LR: 0.001000\n",
      "Epoch: 117\n",
      "\tTrain:\tTotal Loss: 1.3923, Feature Loss: 1.3923,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.1070, Feature Loss: 1.1070, , LR: 0.001000\n",
      "Epoch: 118\n",
      "\tTrain:\tTotal Loss: 1.3824, Feature Loss: 1.3824,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.1250, Feature Loss: 1.1250, , LR: 0.001000\n",
      "Epoch: 119\n",
      "\tTrain:\tTotal Loss: 1.3741, Feature Loss: 1.3741,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.1032, Feature Loss: 1.1032, , LR: 0.001000\n",
      "Epoch: 120\n",
      "\tTrain:\tTotal Loss: 1.3677, Feature Loss: 1.3677,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0992, Feature Loss: 1.0992, , LR: 0.001000\n",
      "Epoch: 121\n",
      "\tTrain:\tTotal Loss: 1.3644, Feature Loss: 1.3644,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.1053, Feature Loss: 1.1053, , LR: 0.001000\n",
      "Epoch: 122\n",
      "\tTrain:\tTotal Loss: 1.3558, Feature Loss: 1.3558,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0970, Feature Loss: 1.0970, , LR: 0.001000\n",
      "Epoch: 123\n",
      "\tTrain:\tTotal Loss: 1.3546, Feature Loss: 1.3546,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0949, Feature Loss: 1.0949, , LR: 0.001000\n",
      "Epoch: 124\n",
      "\tTrain:\tTotal Loss: 1.3471, Feature Loss: 1.3471,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0878, Feature Loss: 1.0878, , LR: 0.001000\n",
      "Epoch: 125\n",
      "\tTrain:\tTotal Loss: 1.3435, Feature Loss: 1.3435,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0942, Feature Loss: 1.0942, , LR: 0.001000\n",
      "Epoch: 126\n",
      "\tTrain:\tTotal Loss: 1.3428, Feature Loss: 1.3428,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0931, Feature Loss: 1.0931, , LR: 0.001000\n",
      "Epoch: 127\n",
      "\tTrain:\tTotal Loss: 1.3369, Feature Loss: 1.3369,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0829, Feature Loss: 1.0829, , LR: 0.001000\n",
      "Epoch: 128\n",
      "\tTrain:\tTotal Loss: 1.3362, Feature Loss: 1.3362,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0941, Feature Loss: 1.0941, , LR: 0.001000\n",
      "Epoch: 129\n",
      "\tTrain:\tTotal Loss: 1.3322, Feature Loss: 1.3322,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0888, Feature Loss: 1.0888, , LR: 0.001000\n",
      "Epoch: 130\n",
      "\tTrain:\tTotal Loss: 1.3328, Feature Loss: 1.3328,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0885, Feature Loss: 1.0885, , LR: 0.001000\n",
      "Epoch: 131\n",
      "\tTrain:\tTotal Loss: 1.3290, Feature Loss: 1.3290,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.1041, Feature Loss: 1.1041, , LR: 0.001000\n",
      "Epoch: 132\n",
      "\tTrain:\tTotal Loss: 1.3246, Feature Loss: 1.3246,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0826, Feature Loss: 1.0826, , LR: 0.001000\n",
      "Epoch: 133\n",
      "\tTrain:\tTotal Loss: 1.3223, Feature Loss: 1.3223,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0791, Feature Loss: 1.0791, , LR: 0.001000\n",
      "Epoch: 134\n",
      "\tTrain:\tTotal Loss: 1.3169, Feature Loss: 1.3169,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0827, Feature Loss: 1.0827, , LR: 0.001000\n",
      "Epoch: 135\n",
      "\tTrain:\tTotal Loss: 1.3148, Feature Loss: 1.3148,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0848, Feature Loss: 1.0848, , LR: 0.001000\n",
      "Epoch: 136\n",
      "\tTrain:\tTotal Loss: 1.3129, Feature Loss: 1.3129,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0842, Feature Loss: 1.0842, , LR: 0.001000\n",
      "Epoch: 137\n",
      "\tTrain:\tTotal Loss: 1.3128, Feature Loss: 1.3128,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0821, Feature Loss: 1.0821, , LR: 0.001000\n",
      "Epoch: 138\n",
      "\tTrain:\tTotal Loss: 1.3095, Feature Loss: 1.3095,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0836, Feature Loss: 1.0836, , LR: 0.001000\n",
      "Epoch: 139\n",
      "\tTrain:\tTotal Loss: 1.3085, Feature Loss: 1.3085,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0815, Feature Loss: 1.0815, , LR: 0.001000\n",
      "Epoch: 140\n",
      "\tTrain:\tTotal Loss: 1.3088, Feature Loss: 1.3088,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0826, Feature Loss: 1.0826, , LR: 0.001000\n",
      "Epoch: 141\n",
      "\tTrain:\tTotal Loss: 1.3084, Feature Loss: 1.3084,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0839, Feature Loss: 1.0839, , LR: 0.001000\n",
      "Epoch: 142\n",
      "\tTrain:\tTotal Loss: 1.3034, Feature Loss: 1.3034,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0754, Feature Loss: 1.0754, , LR: 0.001000\n",
      "Epoch: 143\n",
      "\tTrain:\tTotal Loss: 1.3035, Feature Loss: 1.3035,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0733, Feature Loss: 1.0733, , LR: 0.001000\n",
      "Epoch: 144\n",
      "\tTrain:\tTotal Loss: 1.3003, Feature Loss: 1.3003,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0810, Feature Loss: 1.0810, , LR: 0.001000\n",
      "Epoch: 145\n",
      "\tTrain:\tTotal Loss: 1.2985, Feature Loss: 1.2985,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0743, Feature Loss: 1.0743, , LR: 0.001000\n",
      "Epoch: 146\n",
      "\tTrain:\tTotal Loss: 1.2988, Feature Loss: 1.2988,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0802, Feature Loss: 1.0802, , LR: 0.001000\n",
      "Epoch: 147\n",
      "\tTrain:\tTotal Loss: 1.2988, Feature Loss: 1.2988,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0763, Feature Loss: 1.0763, , LR: 0.001000\n",
      "Epoch: 148\n",
      "\tTrain:\tTotal Loss: 1.2989, Feature Loss: 1.2989,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0707, Feature Loss: 1.0707, , LR: 0.001000\n",
      "Epoch: 149\n",
      "\tTrain:\tTotal Loss: 1.2948, Feature Loss: 1.2948,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0765, Feature Loss: 1.0765, , LR: 0.001000\n",
      "Epoch: 150\n",
      "\tTrain:\tTotal Loss: 1.2927, Feature Loss: 1.2927,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0705, Feature Loss: 1.0705, , LR: 0.001000\n",
      "Epoch: 151\n",
      "\tTrain:\tTotal Loss: 1.2942, Feature Loss: 1.2942,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0746, Feature Loss: 1.0746, , LR: 0.001000\n",
      "Epoch: 152\n",
      "\tTrain:\tTotal Loss: 1.2912, Feature Loss: 1.2912,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0690, Feature Loss: 1.0690, , LR: 0.001000\n",
      "Epoch: 153\n",
      "\tTrain:\tTotal Loss: 1.2901, Feature Loss: 1.2901,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0713, Feature Loss: 1.0713, , LR: 0.001000\n",
      "Epoch: 154\n",
      "\tTrain:\tTotal Loss: 1.2886, Feature Loss: 1.2886,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0741, Feature Loss: 1.0741, , LR: 0.001000\n",
      "Epoch: 155\n",
      "\tTrain:\tTotal Loss: 1.2875, Feature Loss: 1.2875,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0747, Feature Loss: 1.0747, , LR: 0.001000\n",
      "Epoch: 156\n",
      "\tTrain:\tTotal Loss: 1.2871, Feature Loss: 1.2871,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0734, Feature Loss: 1.0734, , LR: 0.001000\n",
      "Epoch: 157\n",
      "\tTrain:\tTotal Loss: 1.2880, Feature Loss: 1.2880,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0717, Feature Loss: 1.0717, , LR: 0.001000\n",
      "Epoch: 158\n",
      "\tTrain:\tTotal Loss: 1.2855, Feature Loss: 1.2855,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0731, Feature Loss: 1.0731, , LR: 0.001000\n",
      "Epoch: 159\n",
      "\tTrain:\tTotal Loss: 1.2842, Feature Loss: 1.2842,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0711, Feature Loss: 1.0711, , LR: 0.001000\n",
      "Epoch: 160\n",
      "\tTrain:\tTotal Loss: 1.2843, Feature Loss: 1.2843,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0675, Feature Loss: 1.0675, , LR: 0.001000\n",
      "Epoch: 161\n",
      "\tTrain:\tTotal Loss: 1.2846, Feature Loss: 1.2846,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0699, Feature Loss: 1.0699, , LR: 0.001000\n",
      "Epoch: 162\n",
      "\tTrain:\tTotal Loss: 1.2840, Feature Loss: 1.2840,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0640, Feature Loss: 1.0640, , LR: 0.001000\n",
      "Epoch: 163\n",
      "\tTrain:\tTotal Loss: 1.2842, Feature Loss: 1.2842,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0769, Feature Loss: 1.0769, , LR: 0.001000\n",
      "Epoch: 164\n",
      "\tTrain:\tTotal Loss: 1.2806, Feature Loss: 1.2806,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0656, Feature Loss: 1.0656, , LR: 0.001000\n",
      "Epoch: 165\n",
      "\tTrain:\tTotal Loss: 1.2810, Feature Loss: 1.2810,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0679, Feature Loss: 1.0679, , LR: 0.001000\n",
      "Epoch: 166\n",
      "\tTrain:\tTotal Loss: 1.2801, Feature Loss: 1.2801,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0664, Feature Loss: 1.0664, , LR: 0.001000\n",
      "Epoch: 167\n",
      "\tTrain:\tTotal Loss: 1.2783, Feature Loss: 1.2783,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0700, Feature Loss: 1.0700, , LR: 0.001000\n",
      "Epoch: 168\n",
      "\tTrain:\tTotal Loss: 1.2777, Feature Loss: 1.2777,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0682, Feature Loss: 1.0682, , LR: 0.001000\n",
      "Epoch: 169\n",
      "\tTrain:\tTotal Loss: 1.2758, Feature Loss: 1.2758,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0657, Feature Loss: 1.0657, , LR: 0.001000\n",
      "Epoch: 170\n",
      "\tTrain:\tTotal Loss: 1.2745, Feature Loss: 1.2745,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0663, Feature Loss: 1.0663, , LR: 0.001000\n",
      "Epoch: 171\n",
      "\tTrain:\tTotal Loss: 1.2746, Feature Loss: 1.2746,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0632, Feature Loss: 1.0632, , LR: 0.001000\n",
      "Epoch: 172\n",
      "\tTrain:\tTotal Loss: 1.2731, Feature Loss: 1.2731,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0646, Feature Loss: 1.0646, , LR: 0.001000\n",
      "Epoch: 173\n",
      "\tTrain:\tTotal Loss: 1.2738, Feature Loss: 1.2738,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0657, Feature Loss: 1.0657, , LR: 0.001000\n",
      "Epoch: 174\n",
      "\tTrain:\tTotal Loss: 1.2721, Feature Loss: 1.2721,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0641, Feature Loss: 1.0641, , LR: 0.001000\n",
      "Epoch: 175\n",
      "\tTrain:\tTotal Loss: 1.2726, Feature Loss: 1.2726,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0571, Feature Loss: 1.0571, , LR: 0.001000\n",
      "Epoch: 176\n",
      "\tTrain:\tTotal Loss: 1.2706, Feature Loss: 1.2706,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0645, Feature Loss: 1.0645, , LR: 0.001000\n",
      "Epoch: 177\n",
      "\tTrain:\tTotal Loss: 1.2695, Feature Loss: 1.2695,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0647, Feature Loss: 1.0647, , LR: 0.001000\n",
      "Epoch: 178\n",
      "\tTrain:\tTotal Loss: 1.2692, Feature Loss: 1.2692,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0654, Feature Loss: 1.0654, , LR: 0.001000\n",
      "Epoch: 179\n",
      "\tTrain:\tTotal Loss: 1.2685, Feature Loss: 1.2685,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0596, Feature Loss: 1.0596, , LR: 0.001000\n",
      "Epoch: 180\n",
      "\tTrain:\tTotal Loss: 1.2674, Feature Loss: 1.2674,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0601, Feature Loss: 1.0601, , LR: 0.001000\n",
      "Epoch: 181\n",
      "\tTrain:\tTotal Loss: 1.2674, Feature Loss: 1.2674,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0609, Feature Loss: 1.0609, , LR: 0.001000\n",
      "Epoch: 182\n",
      "\tTrain:\tTotal Loss: 1.2659, Feature Loss: 1.2659,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0649, Feature Loss: 1.0649, , LR: 0.001000\n",
      "Epoch: 183\n",
      "\tTrain:\tTotal Loss: 1.2655, Feature Loss: 1.2655,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0623, Feature Loss: 1.0623, , LR: 0.001000\n",
      "Epoch: 184\n",
      "\tTrain:\tTotal Loss: 1.2650, Feature Loss: 1.2650,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0611, Feature Loss: 1.0611, , LR: 0.001000\n",
      "Epoch: 185\n",
      "\tTrain:\tTotal Loss: 1.2647, Feature Loss: 1.2647,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0574, Feature Loss: 1.0574, , LR: 0.001000\n",
      "Epoch: 186\n",
      "\tTrain:\tTotal Loss: 1.2631, Feature Loss: 1.2631,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0615, Feature Loss: 1.0615, , LR: 0.001000\n",
      "Epoch: 187\n",
      "\tTrain:\tTotal Loss: 1.2630, Feature Loss: 1.2630,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0574, Feature Loss: 1.0574, , LR: 0.001000\n",
      "Epoch: 188\n",
      "\tTrain:\tTotal Loss: 1.2626, Feature Loss: 1.2626,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0618, Feature Loss: 1.0618, , LR: 0.001000\n",
      "Epoch: 189\n",
      "\tTrain:\tTotal Loss: 1.2618, Feature Loss: 1.2618,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0613, Feature Loss: 1.0613, , LR: 0.001000\n",
      "Epoch: 190\n",
      "\tTrain:\tTotal Loss: 1.2623, Feature Loss: 1.2623,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0549, Feature Loss: 1.0549, , LR: 0.001000\n",
      "Epoch: 191\n",
      "\tTrain:\tTotal Loss: 1.2609, Feature Loss: 1.2609,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0587, Feature Loss: 1.0587, , LR: 0.001000\n",
      "Epoch: 192\n",
      "\tTrain:\tTotal Loss: 1.2606, Feature Loss: 1.2606,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0550, Feature Loss: 1.0550, , LR: 0.001000\n",
      "Epoch: 193\n",
      "\tTrain:\tTotal Loss: 1.2581, Feature Loss: 1.2581,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0567, Feature Loss: 1.0567, , LR: 0.001000\n",
      "Epoch: 194\n",
      "\tTrain:\tTotal Loss: 1.2579, Feature Loss: 1.2579,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0601, Feature Loss: 1.0601, , LR: 0.001000\n",
      "Epoch: 195\n",
      "\tTrain:\tTotal Loss: 1.2579, Feature Loss: 1.2579,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0560, Feature Loss: 1.0560, , LR: 0.001000\n",
      "Epoch: 196\n",
      "\tTrain:\tTotal Loss: 1.2570, Feature Loss: 1.2570,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0559, Feature Loss: 1.0559, , LR: 0.001000\n",
      "Epoch: 197\n",
      "\tTrain:\tTotal Loss: 1.2560, Feature Loss: 1.2560,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0565, Feature Loss: 1.0565, , LR: 0.001000\n",
      "Epoch: 198\n",
      "\tTrain:\tTotal Loss: 1.2554, Feature Loss: 1.2554,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0566, Feature Loss: 1.0566, , LR: 0.001000\n",
      "Epoch: 199\n",
      "\tTrain:\tTotal Loss: 1.2559, Feature Loss: 1.2559,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0544, Feature Loss: 1.0544, , LR: 0.001000\n",
      "Epoch: 200\n",
      "\tTrain:\tTotal Loss: 1.2537, Feature Loss: 1.2537,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0565, Feature Loss: 1.0565, , LR: 0.001000\n",
      "Epoch: 201\n",
      "\tTrain:\tTotal Loss: 1.2534, Feature Loss: 1.2534,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0581, Feature Loss: 1.0581, , LR: 0.001000\n",
      "Epoch: 202\n",
      "\tTrain:\tTotal Loss: 1.2527, Feature Loss: 1.2527,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0509, Feature Loss: 1.0509, , LR: 0.001000\n",
      "Epoch: 203\n",
      "\tTrain:\tTotal Loss: 1.2523, Feature Loss: 1.2523,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0561, Feature Loss: 1.0561, , LR: 0.001000\n",
      "Epoch: 204\n",
      "\tTrain:\tTotal Loss: 1.2511, Feature Loss: 1.2511,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0515, Feature Loss: 1.0515, , LR: 0.001000\n",
      "Epoch: 205\n",
      "\tTrain:\tTotal Loss: 1.2517, Feature Loss: 1.2517,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0519, Feature Loss: 1.0519, , LR: 0.001000\n",
      "Epoch: 206\n",
      "\tTrain:\tTotal Loss: 1.2497, Feature Loss: 1.2497,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0482, Feature Loss: 1.0482, , LR: 0.001000\n",
      "Epoch: 207\n",
      "\tTrain:\tTotal Loss: 1.2487, Feature Loss: 1.2487,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0495, Feature Loss: 1.0495, , LR: 0.001000\n",
      "Epoch: 208\n",
      "\tTrain:\tTotal Loss: 1.2486, Feature Loss: 1.2486,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0507, Feature Loss: 1.0507, , LR: 0.001000\n",
      "Epoch: 209\n",
      "\tTrain:\tTotal Loss: 1.2480, Feature Loss: 1.2480,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0493, Feature Loss: 1.0493, , LR: 0.001000\n",
      "Epoch: 210\n",
      "\tTrain:\tTotal Loss: 1.2473, Feature Loss: 1.2473,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0522, Feature Loss: 1.0522, , LR: 0.001000\n",
      "Epoch: 211\n",
      "\tTrain:\tTotal Loss: 1.2469, Feature Loss: 1.2469,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0457, Feature Loss: 1.0457, , LR: 0.001000\n",
      "Epoch: 212\n",
      "\tTrain:\tTotal Loss: 1.2458, Feature Loss: 1.2458,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0518, Feature Loss: 1.0518, , LR: 0.001000\n",
      "Epoch: 213\n",
      "\tTrain:\tTotal Loss: 1.2451, Feature Loss: 1.2451,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0502, Feature Loss: 1.0502, , LR: 0.001000\n",
      "Epoch: 214\n",
      "\tTrain:\tTotal Loss: 1.2444, Feature Loss: 1.2444,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0472, Feature Loss: 1.0472, , LR: 0.001000\n",
      "Epoch: 215\n",
      "\tTrain:\tTotal Loss: 1.2438, Feature Loss: 1.2438,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0479, Feature Loss: 1.0479, , LR: 0.001000\n",
      "Epoch: 216\n",
      "\tTrain:\tTotal Loss: 1.2432, Feature Loss: 1.2432,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0474, Feature Loss: 1.0474, , LR: 0.001000\n",
      "Epoch: 217\n",
      "\tTrain:\tTotal Loss: 1.2423, Feature Loss: 1.2423,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0462, Feature Loss: 1.0462, , LR: 0.001000\n",
      "Epoch: 218\n",
      "\tTrain:\tTotal Loss: 1.2423, Feature Loss: 1.2423,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0490, Feature Loss: 1.0490, , LR: 0.001000\n",
      "Epoch: 219\n",
      "\tTrain:\tTotal Loss: 1.2413, Feature Loss: 1.2413,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0494, Feature Loss: 1.0494, , LR: 0.001000\n",
      "Epoch: 220\n",
      "\tTrain:\tTotal Loss: 1.2417, Feature Loss: 1.2417,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0439, Feature Loss: 1.0439, , LR: 0.001000\n",
      "Epoch: 221\n",
      "\tTrain:\tTotal Loss: 1.2404, Feature Loss: 1.2404,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0494, Feature Loss: 1.0494, , LR: 0.001000\n",
      "Epoch: 222\n",
      "\tTrain:\tTotal Loss: 1.2405, Feature Loss: 1.2405,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0422, Feature Loss: 1.0422, , LR: 0.001000\n",
      "Epoch: 223\n",
      "\tTrain:\tTotal Loss: 1.2390, Feature Loss: 1.2390,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0432, Feature Loss: 1.0432, , LR: 0.001000\n",
      "Epoch: 224\n",
      "\tTrain:\tTotal Loss: 1.2385, Feature Loss: 1.2385,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0439, Feature Loss: 1.0439, , LR: 0.001000\n",
      "Epoch: 225\n",
      "\tTrain:\tTotal Loss: 1.2378, Feature Loss: 1.2378,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0403, Feature Loss: 1.0403, , LR: 0.001000\n",
      "Epoch: 226\n",
      "\tTrain:\tTotal Loss: 1.2374, Feature Loss: 1.2374,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0457, Feature Loss: 1.0457, , LR: 0.001000\n",
      "Epoch: 227\n",
      "\tTrain:\tTotal Loss: 1.2363, Feature Loss: 1.2363,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0455, Feature Loss: 1.0455, , LR: 0.001000\n",
      "Epoch: 228\n",
      "\tTrain:\tTotal Loss: 1.2357, Feature Loss: 1.2357,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0424, Feature Loss: 1.0424, , LR: 0.001000\n",
      "Epoch: 229\n",
      "\tTrain:\tTotal Loss: 1.2344, Feature Loss: 1.2344,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0397, Feature Loss: 1.0397, , LR: 0.001000\n",
      "Epoch: 230\n",
      "\tTrain:\tTotal Loss: 1.2344, Feature Loss: 1.2344,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0433, Feature Loss: 1.0433, , LR: 0.001000\n",
      "Epoch: 231\n",
      "\tTrain:\tTotal Loss: 1.2348, Feature Loss: 1.2348,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0420, Feature Loss: 1.0420, , LR: 0.001000\n",
      "Epoch: 232\n",
      "\tTrain:\tTotal Loss: 1.2333, Feature Loss: 1.2333,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0431, Feature Loss: 1.0431, , LR: 0.001000\n",
      "Epoch: 233\n",
      "\tTrain:\tTotal Loss: 1.2323, Feature Loss: 1.2323,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0418, Feature Loss: 1.0418, , LR: 0.001000\n",
      "Epoch: 234\n",
      "\tTrain:\tTotal Loss: 1.2317, Feature Loss: 1.2317,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0390, Feature Loss: 1.0390, , LR: 0.001000\n",
      "Epoch: 235\n",
      "\tTrain:\tTotal Loss: 1.2312, Feature Loss: 1.2312,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0390, Feature Loss: 1.0390, , LR: 0.001000\n",
      "Epoch: 236\n",
      "\tTrain:\tTotal Loss: 1.2314, Feature Loss: 1.2314,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0429, Feature Loss: 1.0429, , LR: 0.001000\n",
      "Epoch: 237\n",
      "\tTrain:\tTotal Loss: 1.2296, Feature Loss: 1.2296,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0358, Feature Loss: 1.0358, , LR: 0.001000\n",
      "Epoch: 238\n",
      "\tTrain:\tTotal Loss: 1.2299, Feature Loss: 1.2299,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0382, Feature Loss: 1.0382, , LR: 0.001000\n",
      "Epoch: 239\n",
      "\tTrain:\tTotal Loss: 1.2284, Feature Loss: 1.2284,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0373, Feature Loss: 1.0373, , LR: 0.001000\n",
      "Epoch: 240\n",
      "\tTrain:\tTotal Loss: 1.2276, Feature Loss: 1.2276,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0397, Feature Loss: 1.0397, , LR: 0.001000\n",
      "Epoch: 241\n",
      "\tTrain:\tTotal Loss: 1.2272, Feature Loss: 1.2272,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0369, Feature Loss: 1.0369, , LR: 0.001000\n",
      "Epoch: 242\n",
      "\tTrain:\tTotal Loss: 1.2272, Feature Loss: 1.2272,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0344, Feature Loss: 1.0344, , LR: 0.001000\n",
      "Epoch: 243\n",
      "\tTrain:\tTotal Loss: 1.2263, Feature Loss: 1.2263,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0419, Feature Loss: 1.0419, , LR: 0.001000\n",
      "Epoch: 244\n",
      "\tTrain:\tTotal Loss: 1.2260, Feature Loss: 1.2260,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0347, Feature Loss: 1.0347, , LR: 0.001000\n",
      "Epoch: 245\n",
      "\tTrain:\tTotal Loss: 1.2253, Feature Loss: 1.2253,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0350, Feature Loss: 1.0350, , LR: 0.001000\n",
      "Epoch: 246\n",
      "\tTrain:\tTotal Loss: 1.2239, Feature Loss: 1.2239,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0392, Feature Loss: 1.0392, , LR: 0.001000\n",
      "Epoch: 247\n",
      "\tTrain:\tTotal Loss: 1.2240, Feature Loss: 1.2240,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0354, Feature Loss: 1.0354, , LR: 0.001000\n",
      "Epoch: 248\n",
      "\tTrain:\tTotal Loss: 1.2230, Feature Loss: 1.2230,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0334, Feature Loss: 1.0334, , LR: 0.001000\n",
      "Epoch: 249\n",
      "\tTrain:\tTotal Loss: 1.2232, Feature Loss: 1.2232,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0382, Feature Loss: 1.0382, , LR: 0.001000\n",
      "Epoch: 250\n",
      "\tTrain:\tTotal Loss: 1.2240, Feature Loss: 1.2240,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0329, Feature Loss: 1.0329, , LR: 0.001000\n",
      "Epoch: 251\n",
      "\tTrain:\tTotal Loss: 1.2214, Feature Loss: 1.2214,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0314, Feature Loss: 1.0314, , LR: 0.001000\n",
      "Epoch: 252\n",
      "\tTrain:\tTotal Loss: 1.2206, Feature Loss: 1.2206,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0354, Feature Loss: 1.0354, , LR: 0.001000\n",
      "Epoch: 253\n",
      "\tTrain:\tTotal Loss: 1.2211, Feature Loss: 1.2211,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0294, Feature Loss: 1.0294, , LR: 0.001000\n",
      "Epoch: 254\n",
      "\tTrain:\tTotal Loss: 1.2212, Feature Loss: 1.2212,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0374, Feature Loss: 1.0374, , LR: 0.001000\n",
      "Epoch: 255\n",
      "\tTrain:\tTotal Loss: 1.2191, Feature Loss: 1.2191,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0310, Feature Loss: 1.0310, , LR: 0.001000\n",
      "Epoch: 256\n",
      "\tTrain:\tTotal Loss: 1.2180, Feature Loss: 1.2180,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0334, Feature Loss: 1.0334, , LR: 0.001000\n",
      "Epoch: 257\n",
      "\tTrain:\tTotal Loss: 1.2178, Feature Loss: 1.2178,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0355, Feature Loss: 1.0355, , LR: 0.001000\n",
      "Epoch: 258\n",
      "\tTrain:\tTotal Loss: 1.2163, Feature Loss: 1.2163,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0293, Feature Loss: 1.0293, , LR: 0.001000\n",
      "Epoch: 259\n",
      "\tTrain:\tTotal Loss: 1.2160, Feature Loss: 1.2160,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0313, Feature Loss: 1.0313, , LR: 0.001000\n",
      "Epoch: 260\n",
      "\tTrain:\tTotal Loss: 1.2157, Feature Loss: 1.2157,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0301, Feature Loss: 1.0301, , LR: 0.001000\n",
      "Epoch: 261\n",
      "\tTrain:\tTotal Loss: 1.2153, Feature Loss: 1.2153,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0313, Feature Loss: 1.0313, , LR: 0.001000\n",
      "Epoch: 262\n",
      "\tTrain:\tTotal Loss: 1.2141, Feature Loss: 1.2141,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0286, Feature Loss: 1.0286, , LR: 0.001000\n",
      "Epoch: 263\n",
      "\tTrain:\tTotal Loss: 1.2134, Feature Loss: 1.2134,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0295, Feature Loss: 1.0295, , LR: 0.001000\n",
      "Epoch: 264\n",
      "\tTrain:\tTotal Loss: 1.2127, Feature Loss: 1.2127,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0278, Feature Loss: 1.0278, , LR: 0.001000\n",
      "Epoch: 265\n",
      "\tTrain:\tTotal Loss: 1.2126, Feature Loss: 1.2126,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0277, Feature Loss: 1.0277, , LR: 0.001000\n",
      "Epoch: 266\n",
      "\tTrain:\tTotal Loss: 1.2120, Feature Loss: 1.2120,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0265, Feature Loss: 1.0265, , LR: 0.001000\n",
      "Epoch: 267\n",
      "\tTrain:\tTotal Loss: 1.2110, Feature Loss: 1.2110,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0272, Feature Loss: 1.0272, , LR: 0.001000\n",
      "Epoch: 268\n",
      "\tTrain:\tTotal Loss: 1.2105, Feature Loss: 1.2105,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0278, Feature Loss: 1.0278, , LR: 0.001000\n",
      "Epoch: 269\n",
      "\tTrain:\tTotal Loss: 1.2098, Feature Loss: 1.2098,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0255, Feature Loss: 1.0255, , LR: 0.001000\n",
      "Epoch: 270\n",
      "\tTrain:\tTotal Loss: 1.2092, Feature Loss: 1.2092,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0254, Feature Loss: 1.0254, , LR: 0.001000\n",
      "Epoch: 271\n",
      "\tTrain:\tTotal Loss: 1.2088, Feature Loss: 1.2088,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0272, Feature Loss: 1.0272, , LR: 0.001000\n",
      "Epoch: 272\n",
      "\tTrain:\tTotal Loss: 1.2084, Feature Loss: 1.2084,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0267, Feature Loss: 1.0267, , LR: 0.001000\n",
      "Epoch: 273\n",
      "\tTrain:\tTotal Loss: 1.2070, Feature Loss: 1.2070,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0213, Feature Loss: 1.0213, , LR: 0.001000\n",
      "Epoch: 274\n",
      "\tTrain:\tTotal Loss: 1.2073, Feature Loss: 1.2073,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0238, Feature Loss: 1.0238, , LR: 0.001000\n",
      "Epoch: 275\n",
      "\tTrain:\tTotal Loss: 1.2072, Feature Loss: 1.2072,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0251, Feature Loss: 1.0251, , LR: 0.001000\n",
      "Epoch: 276\n",
      "\tTrain:\tTotal Loss: 1.2072, Feature Loss: 1.2072,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0201, Feature Loss: 1.0201, , LR: 0.001000\n",
      "Epoch: 277\n",
      "\tTrain:\tTotal Loss: 1.2057, Feature Loss: 1.2057,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0251, Feature Loss: 1.0251, , LR: 0.001000\n",
      "Epoch: 278\n",
      "\tTrain:\tTotal Loss: 1.2048, Feature Loss: 1.2048,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0198, Feature Loss: 1.0198, , LR: 0.001000\n",
      "Epoch: 279\n",
      "\tTrain:\tTotal Loss: 1.2050, Feature Loss: 1.2050,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0241, Feature Loss: 1.0241, , LR: 0.001000\n",
      "Epoch: 280\n",
      "\tTrain:\tTotal Loss: 1.2034, Feature Loss: 1.2034,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0209, Feature Loss: 1.0209, , LR: 0.001000\n",
      "Epoch: 281\n",
      "\tTrain:\tTotal Loss: 1.2029, Feature Loss: 1.2029,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0213, Feature Loss: 1.0213, , LR: 0.001000\n",
      "Epoch: 282\n",
      "\tTrain:\tTotal Loss: 1.2027, Feature Loss: 1.2027,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0230, Feature Loss: 1.0230, , LR: 0.001000\n",
      "Epoch: 283\n",
      "\tTrain:\tTotal Loss: 1.2015, Feature Loss: 1.2015,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0206, Feature Loss: 1.0206, , LR: 0.001000\n",
      "Epoch: 284\n",
      "\tTrain:\tTotal Loss: 1.2012, Feature Loss: 1.2012,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0177, Feature Loss: 1.0177, , LR: 0.001000\n",
      "Epoch: 285\n",
      "\tTrain:\tTotal Loss: 1.2007, Feature Loss: 1.2007,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0231, Feature Loss: 1.0231, , LR: 0.001000\n",
      "Epoch: 286\n",
      "\tTrain:\tTotal Loss: 1.2004, Feature Loss: 1.2004,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0154, Feature Loss: 1.0154, , LR: 0.001000\n",
      "Epoch: 287\n",
      "\tTrain:\tTotal Loss: 1.1991, Feature Loss: 1.1991,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0222, Feature Loss: 1.0222, , LR: 0.001000\n",
      "Epoch: 288\n",
      "\tTrain:\tTotal Loss: 1.1986, Feature Loss: 1.1986,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0190, Feature Loss: 1.0190, , LR: 0.001000\n",
      "Epoch: 289\n",
      "\tTrain:\tTotal Loss: 1.1977, Feature Loss: 1.1977,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0186, Feature Loss: 1.0186, , LR: 0.001000\n",
      "Epoch: 290\n",
      "\tTrain:\tTotal Loss: 1.1975, Feature Loss: 1.1975,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0194, Feature Loss: 1.0194, , LR: 0.001000\n",
      "Epoch: 291\n",
      "\tTrain:\tTotal Loss: 1.1968, Feature Loss: 1.1968,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0180, Feature Loss: 1.0180, , LR: 0.001000\n",
      "Epoch: 292\n",
      "\tTrain:\tTotal Loss: 1.1974, Feature Loss: 1.1974,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0147, Feature Loss: 1.0147, , LR: 0.001000\n",
      "Epoch: 293\n",
      "\tTrain:\tTotal Loss: 1.1972, Feature Loss: 1.1972,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0192, Feature Loss: 1.0192, , LR: 0.001000\n",
      "Epoch: 294\n",
      "\tTrain:\tTotal Loss: 1.1948, Feature Loss: 1.1948,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0155, Feature Loss: 1.0155, , LR: 0.001000\n",
      "Epoch: 295\n",
      "\tTrain:\tTotal Loss: 1.1944, Feature Loss: 1.1944,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0145, Feature Loss: 1.0145, , LR: 0.001000\n",
      "Epoch: 296\n",
      "\tTrain:\tTotal Loss: 1.1942, Feature Loss: 1.1942,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0154, Feature Loss: 1.0154, , LR: 0.001000\n",
      "Epoch: 297\n",
      "\tTrain:\tTotal Loss: 1.1929, Feature Loss: 1.1929,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0161, Feature Loss: 1.0161, , LR: 0.001000\n",
      "Epoch: 298\n",
      "\tTrain:\tTotal Loss: 1.1927, Feature Loss: 1.1927,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0143, Feature Loss: 1.0143, , LR: 0.001000\n",
      "Epoch: 299\n",
      "\tTrain:\tTotal Loss: 1.1920, Feature Loss: 1.1920,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0160, Feature Loss: 1.0160, , LR: 0.001000\n",
      "Epoch: 300\n",
      "\tTrain:\tTotal Loss: 1.1918, Feature Loss: 1.1918,  LR: 0.001000\n",
      "\tTest: \tTotal Loss: 1.0146, Feature Loss: 1.0146, , LR: 0.001000\n",
      "Epoch: 301\n",
      "\tTrain:\tTotal Loss: 1.1908, Feature Loss: 1.1908,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0143, Feature Loss: 1.0143, , LR: 0.000500\n",
      "Epoch: 302\n",
      "\tTrain:\tTotal Loss: 1.1907, Feature Loss: 1.1907,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0133, Feature Loss: 1.0133, , LR: 0.000500\n",
      "Epoch: 303\n",
      "\tTrain:\tTotal Loss: 1.1901, Feature Loss: 1.1901,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0140, Feature Loss: 1.0140, , LR: 0.000500\n",
      "Epoch: 304\n",
      "\tTrain:\tTotal Loss: 1.1900, Feature Loss: 1.1900,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0117, Feature Loss: 1.0117, , LR: 0.000500\n",
      "Epoch: 305\n",
      "\tTrain:\tTotal Loss: 1.1895, Feature Loss: 1.1895,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0126, Feature Loss: 1.0126, , LR: 0.000500\n",
      "Epoch: 306\n",
      "\tTrain:\tTotal Loss: 1.1895, Feature Loss: 1.1895,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0140, Feature Loss: 1.0140, , LR: 0.000500\n",
      "Epoch: 307\n",
      "\tTrain:\tTotal Loss: 1.1890, Feature Loss: 1.1890,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0125, Feature Loss: 1.0125, , LR: 0.000500\n",
      "Epoch: 308\n",
      "\tTrain:\tTotal Loss: 1.1886, Feature Loss: 1.1886,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0119, Feature Loss: 1.0119, , LR: 0.000500\n",
      "Epoch: 309\n",
      "\tTrain:\tTotal Loss: 1.1884, Feature Loss: 1.1884,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0116, Feature Loss: 1.0116, , LR: 0.000500\n",
      "Epoch: 310\n",
      "\tTrain:\tTotal Loss: 1.1882, Feature Loss: 1.1882,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0128, Feature Loss: 1.0128, , LR: 0.000500\n",
      "Epoch: 311\n",
      "\tTrain:\tTotal Loss: 1.1880, Feature Loss: 1.1880,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0123, Feature Loss: 1.0123, , LR: 0.000500\n",
      "Epoch: 312\n",
      "\tTrain:\tTotal Loss: 1.1877, Feature Loss: 1.1877,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0104, Feature Loss: 1.0104, , LR: 0.000500\n",
      "Epoch: 313\n",
      "\tTrain:\tTotal Loss: 1.1877, Feature Loss: 1.1877,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0115, Feature Loss: 1.0115, , LR: 0.000500\n",
      "Epoch: 314\n",
      "\tTrain:\tTotal Loss: 1.1869, Feature Loss: 1.1869,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0110, Feature Loss: 1.0110, , LR: 0.000500\n",
      "Epoch: 315\n",
      "\tTrain:\tTotal Loss: 1.1866, Feature Loss: 1.1866,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0113, Feature Loss: 1.0113, , LR: 0.000500\n",
      "Epoch: 316\n",
      "\tTrain:\tTotal Loss: 1.1866, Feature Loss: 1.1866,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0106, Feature Loss: 1.0106, , LR: 0.000500\n",
      "Epoch: 317\n",
      "\tTrain:\tTotal Loss: 1.1862, Feature Loss: 1.1862,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0113, Feature Loss: 1.0113, , LR: 0.000500\n",
      "Epoch: 318\n",
      "\tTrain:\tTotal Loss: 1.1861, Feature Loss: 1.1861,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0111, Feature Loss: 1.0111, , LR: 0.000500\n",
      "Epoch: 319\n",
      "\tTrain:\tTotal Loss: 1.1856, Feature Loss: 1.1856,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0122, Feature Loss: 1.0122, , LR: 0.000500\n",
      "Epoch: 320\n",
      "\tTrain:\tTotal Loss: 1.1850, Feature Loss: 1.1850,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0100, Feature Loss: 1.0100, , LR: 0.000500\n",
      "Epoch: 321\n",
      "\tTrain:\tTotal Loss: 1.1850, Feature Loss: 1.1850,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0096, Feature Loss: 1.0096, , LR: 0.000500\n",
      "Epoch: 322\n",
      "\tTrain:\tTotal Loss: 1.1847, Feature Loss: 1.1847,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0104, Feature Loss: 1.0104, , LR: 0.000500\n",
      "Epoch: 323\n",
      "\tTrain:\tTotal Loss: 1.1842, Feature Loss: 1.1842,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0099, Feature Loss: 1.0099, , LR: 0.000500\n",
      "Epoch: 324\n",
      "\tTrain:\tTotal Loss: 1.1841, Feature Loss: 1.1841,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0090, Feature Loss: 1.0090, , LR: 0.000500\n",
      "Epoch: 325\n",
      "\tTrain:\tTotal Loss: 1.1841, Feature Loss: 1.1841,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0075, Feature Loss: 1.0075, , LR: 0.000500\n",
      "Epoch: 326\n",
      "\tTrain:\tTotal Loss: 1.1839, Feature Loss: 1.1839,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0110, Feature Loss: 1.0110, , LR: 0.000500\n",
      "Epoch: 327\n",
      "\tTrain:\tTotal Loss: 1.1832, Feature Loss: 1.1832,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0082, Feature Loss: 1.0082, , LR: 0.000500\n",
      "Epoch: 328\n",
      "\tTrain:\tTotal Loss: 1.1830, Feature Loss: 1.1830,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0097, Feature Loss: 1.0097, , LR: 0.000500\n",
      "Epoch: 329\n",
      "\tTrain:\tTotal Loss: 1.1826, Feature Loss: 1.1826,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0095, Feature Loss: 1.0095, , LR: 0.000500\n",
      "Epoch: 330\n",
      "\tTrain:\tTotal Loss: 1.1826, Feature Loss: 1.1826,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0091, Feature Loss: 1.0091, , LR: 0.000500\n",
      "Epoch: 331\n",
      "\tTrain:\tTotal Loss: 1.1820, Feature Loss: 1.1820,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0073, Feature Loss: 1.0073, , LR: 0.000500\n",
      "Epoch: 332\n",
      "\tTrain:\tTotal Loss: 1.1819, Feature Loss: 1.1819,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0079, Feature Loss: 1.0079, , LR: 0.000500\n",
      "Epoch: 333\n",
      "\tTrain:\tTotal Loss: 1.1813, Feature Loss: 1.1813,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0067, Feature Loss: 1.0067, , LR: 0.000500\n",
      "Epoch: 334\n",
      "\tTrain:\tTotal Loss: 1.1813, Feature Loss: 1.1813,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0080, Feature Loss: 1.0080, , LR: 0.000500\n",
      "Epoch: 335\n",
      "\tTrain:\tTotal Loss: 1.1806, Feature Loss: 1.1806,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0066, Feature Loss: 1.0066, , LR: 0.000500\n",
      "Epoch: 336\n",
      "\tTrain:\tTotal Loss: 1.1812, Feature Loss: 1.1812,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0095, Feature Loss: 1.0095, , LR: 0.000500\n",
      "Epoch: 337\n",
      "\tTrain:\tTotal Loss: 1.1801, Feature Loss: 1.1801,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0067, Feature Loss: 1.0067, , LR: 0.000500\n",
      "Epoch: 338\n",
      "\tTrain:\tTotal Loss: 1.1797, Feature Loss: 1.1797,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0072, Feature Loss: 1.0072, , LR: 0.000500\n",
      "Epoch: 339\n",
      "\tTrain:\tTotal Loss: 1.1796, Feature Loss: 1.1796,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0073, Feature Loss: 1.0073, , LR: 0.000500\n",
      "Epoch: 340\n",
      "\tTrain:\tTotal Loss: 1.1792, Feature Loss: 1.1792,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0064, Feature Loss: 1.0064, , LR: 0.000500\n",
      "Epoch: 341\n",
      "\tTrain:\tTotal Loss: 1.1790, Feature Loss: 1.1790,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0056, Feature Loss: 1.0056, , LR: 0.000500\n",
      "Epoch: 342\n",
      "\tTrain:\tTotal Loss: 1.1788, Feature Loss: 1.1788,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0048, Feature Loss: 1.0048, , LR: 0.000500\n",
      "Epoch: 343\n",
      "\tTrain:\tTotal Loss: 1.1785, Feature Loss: 1.1785,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0062, Feature Loss: 1.0062, , LR: 0.000500\n",
      "Epoch: 344\n",
      "\tTrain:\tTotal Loss: 1.1784, Feature Loss: 1.1784,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0046, Feature Loss: 1.0046, , LR: 0.000500\n",
      "Epoch: 345\n",
      "\tTrain:\tTotal Loss: 1.1779, Feature Loss: 1.1779,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0060, Feature Loss: 1.0060, , LR: 0.000500\n",
      "Epoch: 346\n",
      "\tTrain:\tTotal Loss: 1.1779, Feature Loss: 1.1779,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0045, Feature Loss: 1.0045, , LR: 0.000500\n",
      "Epoch: 347\n",
      "\tTrain:\tTotal Loss: 1.1777, Feature Loss: 1.1777,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0064, Feature Loss: 1.0064, , LR: 0.000500\n",
      "Epoch: 348\n",
      "\tTrain:\tTotal Loss: 1.1773, Feature Loss: 1.1773,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0043, Feature Loss: 1.0043, , LR: 0.000500\n",
      "Epoch: 349\n",
      "\tTrain:\tTotal Loss: 1.1771, Feature Loss: 1.1771,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0053, Feature Loss: 1.0053, , LR: 0.000500\n",
      "Epoch: 350\n",
      "\tTrain:\tTotal Loss: 1.1765, Feature Loss: 1.1765,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0044, Feature Loss: 1.0044, , LR: 0.000500\n",
      "Epoch: 351\n",
      "\tTrain:\tTotal Loss: 1.1760, Feature Loss: 1.1760,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0044, Feature Loss: 1.0044, , LR: 0.000500\n",
      "Epoch: 352\n",
      "\tTrain:\tTotal Loss: 1.1755, Feature Loss: 1.1755,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0033, Feature Loss: 1.0033, , LR: 0.000500\n",
      "Epoch: 353\n",
      "\tTrain:\tTotal Loss: 1.1763, Feature Loss: 1.1763,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0032, Feature Loss: 1.0032, , LR: 0.000500\n",
      "Epoch: 354\n",
      "\tTrain:\tTotal Loss: 1.1753, Feature Loss: 1.1753,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0051, Feature Loss: 1.0051, , LR: 0.000500\n",
      "Epoch: 355\n",
      "\tTrain:\tTotal Loss: 1.1747, Feature Loss: 1.1747,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0040, Feature Loss: 1.0040, , LR: 0.000500\n",
      "Epoch: 356\n",
      "\tTrain:\tTotal Loss: 1.1748, Feature Loss: 1.1748,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0022, Feature Loss: 1.0022, , LR: 0.000500\n",
      "Epoch: 357\n",
      "\tTrain:\tTotal Loss: 1.1754, Feature Loss: 1.1754,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0054, Feature Loss: 1.0054, , LR: 0.000500\n",
      "Epoch: 358\n",
      "\tTrain:\tTotal Loss: 1.1740, Feature Loss: 1.1740,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0019, Feature Loss: 1.0019, , LR: 0.000500\n",
      "Epoch: 359\n",
      "\tTrain:\tTotal Loss: 1.1740, Feature Loss: 1.1740,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0027, Feature Loss: 1.0027, , LR: 0.000500\n",
      "Epoch: 360\n",
      "\tTrain:\tTotal Loss: 1.1735, Feature Loss: 1.1735,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0038, Feature Loss: 1.0038, , LR: 0.000500\n",
      "Epoch: 361\n",
      "\tTrain:\tTotal Loss: 1.1731, Feature Loss: 1.1731,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0030, Feature Loss: 1.0030, , LR: 0.000500\n",
      "Epoch: 362\n",
      "\tTrain:\tTotal Loss: 1.1727, Feature Loss: 1.1727,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0031, Feature Loss: 1.0031, , LR: 0.000500\n",
      "Epoch: 363\n",
      "\tTrain:\tTotal Loss: 1.1726, Feature Loss: 1.1726,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0027, Feature Loss: 1.0027, , LR: 0.000500\n",
      "Epoch: 364\n",
      "\tTrain:\tTotal Loss: 1.1723, Feature Loss: 1.1723,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0004, Feature Loss: 1.0004, , LR: 0.000500\n",
      "Epoch: 365\n",
      "\tTrain:\tTotal Loss: 1.1722, Feature Loss: 1.1722,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0018, Feature Loss: 1.0018, , LR: 0.000500\n",
      "Epoch: 366\n",
      "\tTrain:\tTotal Loss: 1.1717, Feature Loss: 1.1717,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0011, Feature Loss: 1.0011, , LR: 0.000500\n",
      "Epoch: 367\n",
      "\tTrain:\tTotal Loss: 1.1714, Feature Loss: 1.1714,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0010, Feature Loss: 1.0010, , LR: 0.000500\n",
      "Epoch: 368\n",
      "\tTrain:\tTotal Loss: 1.1712, Feature Loss: 1.1712,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0008, Feature Loss: 1.0008, , LR: 0.000500\n",
      "Epoch: 369\n",
      "\tTrain:\tTotal Loss: 1.1707, Feature Loss: 1.1707,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0011, Feature Loss: 1.0011, , LR: 0.000500\n",
      "Epoch: 370\n",
      "\tTrain:\tTotal Loss: 1.1704, Feature Loss: 1.1704,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0012, Feature Loss: 1.0012, , LR: 0.000500\n",
      "Epoch: 371\n",
      "\tTrain:\tTotal Loss: 1.1701, Feature Loss: 1.1701,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0014, Feature Loss: 1.0014, , LR: 0.000500\n",
      "Epoch: 372\n",
      "\tTrain:\tTotal Loss: 1.1697, Feature Loss: 1.1697,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9992, Feature Loss: 0.9992, , LR: 0.000500\n",
      "Epoch: 373\n",
      "\tTrain:\tTotal Loss: 1.1697, Feature Loss: 1.1697,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0000, Feature Loss: 1.0000, , LR: 0.000500\n",
      "Epoch: 374\n",
      "\tTrain:\tTotal Loss: 1.1696, Feature Loss: 1.1696,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0001, Feature Loss: 1.0001, , LR: 0.000500\n",
      "Epoch: 375\n",
      "\tTrain:\tTotal Loss: 1.1689, Feature Loss: 1.1689,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0007, Feature Loss: 1.0007, , LR: 0.000500\n",
      "Epoch: 376\n",
      "\tTrain:\tTotal Loss: 1.1688, Feature Loss: 1.1688,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9999, Feature Loss: 0.9999, , LR: 0.000500\n",
      "Epoch: 377\n",
      "\tTrain:\tTotal Loss: 1.1684, Feature Loss: 1.1684,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9992, Feature Loss: 0.9992, , LR: 0.000500\n",
      "Epoch: 378\n",
      "\tTrain:\tTotal Loss: 1.1682, Feature Loss: 1.1682,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9995, Feature Loss: 0.9995, , LR: 0.000500\n",
      "Epoch: 379\n",
      "\tTrain:\tTotal Loss: 1.1682, Feature Loss: 1.1682,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 1.0011, Feature Loss: 1.0011, , LR: 0.000500\n",
      "Epoch: 380\n",
      "\tTrain:\tTotal Loss: 1.1677, Feature Loss: 1.1677,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9967, Feature Loss: 0.9967, , LR: 0.000500\n",
      "Epoch: 381\n",
      "\tTrain:\tTotal Loss: 1.1675, Feature Loss: 1.1675,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9995, Feature Loss: 0.9995, , LR: 0.000500\n",
      "Epoch: 382\n",
      "\tTrain:\tTotal Loss: 1.1670, Feature Loss: 1.1670,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9988, Feature Loss: 0.9988, , LR: 0.000500\n",
      "Epoch: 383\n",
      "\tTrain:\tTotal Loss: 1.1671, Feature Loss: 1.1671,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9976, Feature Loss: 0.9976, , LR: 0.000500\n",
      "Epoch: 384\n",
      "\tTrain:\tTotal Loss: 1.1671, Feature Loss: 1.1671,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9996, Feature Loss: 0.9996, , LR: 0.000500\n",
      "Epoch: 385\n",
      "\tTrain:\tTotal Loss: 1.1664, Feature Loss: 1.1664,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9995, Feature Loss: 0.9995, , LR: 0.000500\n",
      "Epoch: 386\n",
      "\tTrain:\tTotal Loss: 1.1658, Feature Loss: 1.1658,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9978, Feature Loss: 0.9978, , LR: 0.000500\n",
      "Epoch: 387\n",
      "\tTrain:\tTotal Loss: 1.1659, Feature Loss: 1.1659,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9980, Feature Loss: 0.9980, , LR: 0.000500\n",
      "Epoch: 388\n",
      "\tTrain:\tTotal Loss: 1.1654, Feature Loss: 1.1654,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9978, Feature Loss: 0.9978, , LR: 0.000500\n",
      "Epoch: 389\n",
      "\tTrain:\tTotal Loss: 1.1650, Feature Loss: 1.1650,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9977, Feature Loss: 0.9977, , LR: 0.000500\n",
      "Epoch: 390\n",
      "\tTrain:\tTotal Loss: 1.1651, Feature Loss: 1.1651,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9969, Feature Loss: 0.9969, , LR: 0.000500\n",
      "Epoch: 391\n",
      "\tTrain:\tTotal Loss: 1.1649, Feature Loss: 1.1649,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9968, Feature Loss: 0.9968, , LR: 0.000500\n",
      "Epoch: 392\n",
      "\tTrain:\tTotal Loss: 1.1640, Feature Loss: 1.1640,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9975, Feature Loss: 0.9975, , LR: 0.000500\n",
      "Epoch: 393\n",
      "\tTrain:\tTotal Loss: 1.1644, Feature Loss: 1.1644,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9976, Feature Loss: 0.9976, , LR: 0.000500\n",
      "Epoch: 394\n",
      "\tTrain:\tTotal Loss: 1.1641, Feature Loss: 1.1641,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9959, Feature Loss: 0.9959, , LR: 0.000500\n",
      "Epoch: 395\n",
      "\tTrain:\tTotal Loss: 1.1634, Feature Loss: 1.1634,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9981, Feature Loss: 0.9981, , LR: 0.000500\n",
      "Epoch: 396\n",
      "\tTrain:\tTotal Loss: 1.1634, Feature Loss: 1.1634,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9973, Feature Loss: 0.9973, , LR: 0.000500\n",
      "Epoch: 397\n",
      "\tTrain:\tTotal Loss: 1.1631, Feature Loss: 1.1631,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9958, Feature Loss: 0.9958, , LR: 0.000500\n",
      "Epoch: 398\n",
      "\tTrain:\tTotal Loss: 1.1626, Feature Loss: 1.1626,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9955, Feature Loss: 0.9955, , LR: 0.000500\n",
      "Epoch: 399\n",
      "\tTrain:\tTotal Loss: 1.1623, Feature Loss: 1.1623,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9956, Feature Loss: 0.9956, , LR: 0.000500\n",
      "Epoch: 400\n",
      "\tTrain:\tTotal Loss: 1.1624, Feature Loss: 1.1624,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9947, Feature Loss: 0.9947, , LR: 0.000500\n",
      "Epoch: 401\n",
      "\tTrain:\tTotal Loss: 1.1621, Feature Loss: 1.1621,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9967, Feature Loss: 0.9967, , LR: 0.000500\n",
      "Epoch: 402\n",
      "\tTrain:\tTotal Loss: 1.1614, Feature Loss: 1.1614,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9955, Feature Loss: 0.9955, , LR: 0.000500\n",
      "Epoch: 403\n",
      "\tTrain:\tTotal Loss: 1.1616, Feature Loss: 1.1616,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9943, Feature Loss: 0.9943, , LR: 0.000500\n",
      "Epoch: 404\n",
      "\tTrain:\tTotal Loss: 1.1611, Feature Loss: 1.1611,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9955, Feature Loss: 0.9955, , LR: 0.000500\n",
      "Epoch: 405\n",
      "\tTrain:\tTotal Loss: 1.1608, Feature Loss: 1.1608,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9947, Feature Loss: 0.9947, , LR: 0.000500\n",
      "Epoch: 406\n",
      "\tTrain:\tTotal Loss: 1.1608, Feature Loss: 1.1608,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9939, Feature Loss: 0.9939, , LR: 0.000500\n",
      "Epoch: 407\n",
      "\tTrain:\tTotal Loss: 1.1608, Feature Loss: 1.1608,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9961, Feature Loss: 0.9961, , LR: 0.000500\n",
      "Epoch: 408\n",
      "\tTrain:\tTotal Loss: 1.1601, Feature Loss: 1.1601,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9938, Feature Loss: 0.9938, , LR: 0.000500\n",
      "Epoch: 409\n",
      "\tTrain:\tTotal Loss: 1.1596, Feature Loss: 1.1596,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9937, Feature Loss: 0.9937, , LR: 0.000500\n",
      "Epoch: 410\n",
      "\tTrain:\tTotal Loss: 1.1597, Feature Loss: 1.1597,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9959, Feature Loss: 0.9959, , LR: 0.000500\n",
      "Epoch: 411\n",
      "\tTrain:\tTotal Loss: 1.1594, Feature Loss: 1.1594,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9950, Feature Loss: 0.9950, , LR: 0.000500\n",
      "Epoch: 412\n",
      "\tTrain:\tTotal Loss: 1.1591, Feature Loss: 1.1591,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9941, Feature Loss: 0.9941, , LR: 0.000500\n",
      "Epoch: 413\n",
      "\tTrain:\tTotal Loss: 1.1586, Feature Loss: 1.1586,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9932, Feature Loss: 0.9932, , LR: 0.000500\n",
      "Epoch: 414\n",
      "\tTrain:\tTotal Loss: 1.1584, Feature Loss: 1.1584,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9941, Feature Loss: 0.9941, , LR: 0.000500\n",
      "Epoch: 415\n",
      "\tTrain:\tTotal Loss: 1.1583, Feature Loss: 1.1583,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9949, Feature Loss: 0.9949, , LR: 0.000500\n",
      "Epoch: 416\n",
      "\tTrain:\tTotal Loss: 1.1582, Feature Loss: 1.1582,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9931, Feature Loss: 0.9931, , LR: 0.000500\n",
      "Epoch: 417\n",
      "\tTrain:\tTotal Loss: 1.1578, Feature Loss: 1.1578,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9925, Feature Loss: 0.9925, , LR: 0.000500\n",
      "Epoch: 418\n",
      "\tTrain:\tTotal Loss: 1.1572, Feature Loss: 1.1572,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9924, Feature Loss: 0.9924, , LR: 0.000500\n",
      "Epoch: 419\n",
      "\tTrain:\tTotal Loss: 1.1573, Feature Loss: 1.1573,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9920, Feature Loss: 0.9920, , LR: 0.000500\n",
      "Epoch: 420\n",
      "\tTrain:\tTotal Loss: 1.1571, Feature Loss: 1.1571,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9930, Feature Loss: 0.9930, , LR: 0.000500\n",
      "Epoch: 421\n",
      "\tTrain:\tTotal Loss: 1.1571, Feature Loss: 1.1571,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9935, Feature Loss: 0.9935, , LR: 0.000500\n",
      "Epoch: 422\n",
      "\tTrain:\tTotal Loss: 1.1567, Feature Loss: 1.1567,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9907, Feature Loss: 0.9907, , LR: 0.000500\n",
      "Epoch: 423\n",
      "\tTrain:\tTotal Loss: 1.1564, Feature Loss: 1.1564,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9928, Feature Loss: 0.9928, , LR: 0.000500\n",
      "Epoch: 424\n",
      "\tTrain:\tTotal Loss: 1.1559, Feature Loss: 1.1559,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9920, Feature Loss: 0.9920, , LR: 0.000500\n",
      "Epoch: 425\n",
      "\tTrain:\tTotal Loss: 1.1559, Feature Loss: 1.1559,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9921, Feature Loss: 0.9921, , LR: 0.000500\n",
      "Epoch: 426\n",
      "\tTrain:\tTotal Loss: 1.1554, Feature Loss: 1.1554,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9907, Feature Loss: 0.9907, , LR: 0.000500\n",
      "Epoch: 427\n",
      "\tTrain:\tTotal Loss: 1.1553, Feature Loss: 1.1553,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9922, Feature Loss: 0.9922, , LR: 0.000500\n",
      "Epoch: 428\n",
      "\tTrain:\tTotal Loss: 1.1548, Feature Loss: 1.1548,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9910, Feature Loss: 0.9910, , LR: 0.000500\n",
      "Epoch: 429\n",
      "\tTrain:\tTotal Loss: 1.1549, Feature Loss: 1.1549,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9903, Feature Loss: 0.9903, , LR: 0.000500\n",
      "Epoch: 430\n",
      "\tTrain:\tTotal Loss: 1.1544, Feature Loss: 1.1544,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9907, Feature Loss: 0.9907, , LR: 0.000500\n",
      "Epoch: 431\n",
      "\tTrain:\tTotal Loss: 1.1542, Feature Loss: 1.1542,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9919, Feature Loss: 0.9919, , LR: 0.000500\n",
      "Epoch: 432\n",
      "\tTrain:\tTotal Loss: 1.1541, Feature Loss: 1.1541,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9895, Feature Loss: 0.9895, , LR: 0.000500\n",
      "Epoch: 433\n",
      "\tTrain:\tTotal Loss: 1.1537, Feature Loss: 1.1537,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9907, Feature Loss: 0.9907, , LR: 0.000500\n",
      "Epoch: 434\n",
      "\tTrain:\tTotal Loss: 1.1537, Feature Loss: 1.1537,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9914, Feature Loss: 0.9914, , LR: 0.000500\n",
      "Epoch: 435\n",
      "\tTrain:\tTotal Loss: 1.1536, Feature Loss: 1.1536,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9913, Feature Loss: 0.9913, , LR: 0.000500\n",
      "Epoch: 436\n",
      "\tTrain:\tTotal Loss: 1.1528, Feature Loss: 1.1528,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9907, Feature Loss: 0.9907, , LR: 0.000500\n",
      "Epoch: 437\n",
      "\tTrain:\tTotal Loss: 1.1527, Feature Loss: 1.1527,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9914, Feature Loss: 0.9914, , LR: 0.000500\n",
      "Epoch: 438\n",
      "\tTrain:\tTotal Loss: 1.1525, Feature Loss: 1.1525,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9896, Feature Loss: 0.9896, , LR: 0.000500\n",
      "Epoch: 439\n",
      "\tTrain:\tTotal Loss: 1.1522, Feature Loss: 1.1522,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9901, Feature Loss: 0.9901, , LR: 0.000500\n",
      "Epoch: 440\n",
      "\tTrain:\tTotal Loss: 1.1520, Feature Loss: 1.1520,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9902, Feature Loss: 0.9902, , LR: 0.000500\n",
      "Epoch: 441\n",
      "\tTrain:\tTotal Loss: 1.1522, Feature Loss: 1.1522,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9909, Feature Loss: 0.9909, , LR: 0.000500\n",
      "Epoch: 442\n",
      "\tTrain:\tTotal Loss: 1.1515, Feature Loss: 1.1515,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9884, Feature Loss: 0.9884, , LR: 0.000500\n",
      "Epoch: 443\n",
      "\tTrain:\tTotal Loss: 1.1511, Feature Loss: 1.1511,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9884, Feature Loss: 0.9884, , LR: 0.000500\n",
      "Epoch: 444\n",
      "\tTrain:\tTotal Loss: 1.1509, Feature Loss: 1.1509,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9896, Feature Loss: 0.9896, , LR: 0.000500\n",
      "Epoch: 445\n",
      "\tTrain:\tTotal Loss: 1.1508, Feature Loss: 1.1508,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9890, Feature Loss: 0.9890, , LR: 0.000500\n",
      "Epoch: 446\n",
      "\tTrain:\tTotal Loss: 1.1506, Feature Loss: 1.1506,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9897, Feature Loss: 0.9897, , LR: 0.000500\n",
      "Epoch: 447\n",
      "\tTrain:\tTotal Loss: 1.1503, Feature Loss: 1.1503,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9898, Feature Loss: 0.9898, , LR: 0.000500\n",
      "Epoch: 448\n",
      "\tTrain:\tTotal Loss: 1.1500, Feature Loss: 1.1500,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9886, Feature Loss: 0.9886, , LR: 0.000500\n",
      "Epoch: 449\n",
      "\tTrain:\tTotal Loss: 1.1500, Feature Loss: 1.1500,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9892, Feature Loss: 0.9892, , LR: 0.000500\n",
      "Epoch: 450\n",
      "\tTrain:\tTotal Loss: 1.1495, Feature Loss: 1.1495,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9889, Feature Loss: 0.9889, , LR: 0.000500\n",
      "Epoch: 451\n",
      "\tTrain:\tTotal Loss: 1.1492, Feature Loss: 1.1492,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9879, Feature Loss: 0.9879, , LR: 0.000500\n",
      "Epoch: 452\n",
      "\tTrain:\tTotal Loss: 1.1491, Feature Loss: 1.1491,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9884, Feature Loss: 0.9884, , LR: 0.000500\n",
      "Epoch: 453\n",
      "\tTrain:\tTotal Loss: 1.1489, Feature Loss: 1.1489,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9879, Feature Loss: 0.9879, , LR: 0.000500\n",
      "Epoch: 454\n",
      "\tTrain:\tTotal Loss: 1.1485, Feature Loss: 1.1485,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9885, Feature Loss: 0.9885, , LR: 0.000500\n",
      "Epoch: 455\n",
      "\tTrain:\tTotal Loss: 1.1488, Feature Loss: 1.1488,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9869, Feature Loss: 0.9869, , LR: 0.000500\n",
      "Epoch: 456\n",
      "\tTrain:\tTotal Loss: 1.1482, Feature Loss: 1.1482,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9885, Feature Loss: 0.9885, , LR: 0.000500\n",
      "Epoch: 457\n",
      "\tTrain:\tTotal Loss: 1.1479, Feature Loss: 1.1479,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9874, Feature Loss: 0.9874, , LR: 0.000500\n",
      "Epoch: 458\n",
      "\tTrain:\tTotal Loss: 1.1478, Feature Loss: 1.1478,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9872, Feature Loss: 0.9872, , LR: 0.000500\n",
      "Epoch: 459\n",
      "\tTrain:\tTotal Loss: 1.1476, Feature Loss: 1.1476,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9866, Feature Loss: 0.9866, , LR: 0.000500\n",
      "Epoch: 460\n",
      "\tTrain:\tTotal Loss: 1.1474, Feature Loss: 1.1474,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9878, Feature Loss: 0.9878, , LR: 0.000500\n",
      "Epoch: 461\n",
      "\tTrain:\tTotal Loss: 1.1472, Feature Loss: 1.1472,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9865, Feature Loss: 0.9865, , LR: 0.000500\n",
      "Epoch: 462\n",
      "\tTrain:\tTotal Loss: 1.1472, Feature Loss: 1.1472,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9861, Feature Loss: 0.9861, , LR: 0.000500\n",
      "Epoch: 463\n",
      "\tTrain:\tTotal Loss: 1.1468, Feature Loss: 1.1468,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9870, Feature Loss: 0.9870, , LR: 0.000500\n",
      "Epoch: 464\n",
      "\tTrain:\tTotal Loss: 1.1464, Feature Loss: 1.1464,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9877, Feature Loss: 0.9877, , LR: 0.000500\n",
      "Epoch: 465\n",
      "\tTrain:\tTotal Loss: 1.1464, Feature Loss: 1.1464,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9856, Feature Loss: 0.9856, , LR: 0.000500\n",
      "Epoch: 466\n",
      "\tTrain:\tTotal Loss: 1.1461, Feature Loss: 1.1461,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9869, Feature Loss: 0.9869, , LR: 0.000500\n",
      "Epoch: 467\n",
      "\tTrain:\tTotal Loss: 1.1456, Feature Loss: 1.1456,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9857, Feature Loss: 0.9857, , LR: 0.000500\n",
      "Epoch: 468\n",
      "\tTrain:\tTotal Loss: 1.1453, Feature Loss: 1.1453,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9869, Feature Loss: 0.9869, , LR: 0.000500\n",
      "Epoch: 469\n",
      "\tTrain:\tTotal Loss: 1.1451, Feature Loss: 1.1451,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9856, Feature Loss: 0.9856, , LR: 0.000500\n",
      "Epoch: 470\n",
      "\tTrain:\tTotal Loss: 1.1450, Feature Loss: 1.1450,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9867, Feature Loss: 0.9867, , LR: 0.000500\n",
      "Epoch: 471\n",
      "\tTrain:\tTotal Loss: 1.1447, Feature Loss: 1.1447,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9860, Feature Loss: 0.9860, , LR: 0.000500\n",
      "Epoch: 472\n",
      "\tTrain:\tTotal Loss: 1.1447, Feature Loss: 1.1447,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9856, Feature Loss: 0.9856, , LR: 0.000500\n",
      "Epoch: 473\n",
      "\tTrain:\tTotal Loss: 1.1443, Feature Loss: 1.1443,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9841, Feature Loss: 0.9841, , LR: 0.000500\n",
      "Epoch: 474\n",
      "\tTrain:\tTotal Loss: 1.1441, Feature Loss: 1.1441,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9852, Feature Loss: 0.9852, , LR: 0.000500\n",
      "Epoch: 475\n",
      "\tTrain:\tTotal Loss: 1.1438, Feature Loss: 1.1438,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9840, Feature Loss: 0.9840, , LR: 0.000500\n",
      "Epoch: 476\n",
      "\tTrain:\tTotal Loss: 1.1437, Feature Loss: 1.1437,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9858, Feature Loss: 0.9858, , LR: 0.000500\n",
      "Epoch: 477\n",
      "\tTrain:\tTotal Loss: 1.1436, Feature Loss: 1.1436,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9846, Feature Loss: 0.9846, , LR: 0.000500\n",
      "Epoch: 478\n",
      "\tTrain:\tTotal Loss: 1.1432, Feature Loss: 1.1432,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9863, Feature Loss: 0.9863, , LR: 0.000500\n",
      "Epoch: 479\n",
      "\tTrain:\tTotal Loss: 1.1433, Feature Loss: 1.1433,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9839, Feature Loss: 0.9839, , LR: 0.000500\n",
      "Epoch: 480\n",
      "\tTrain:\tTotal Loss: 1.1432, Feature Loss: 1.1432,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9852, Feature Loss: 0.9852, , LR: 0.000500\n",
      "Epoch: 481\n",
      "\tTrain:\tTotal Loss: 1.1423, Feature Loss: 1.1423,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9845, Feature Loss: 0.9845, , LR: 0.000500\n",
      "Epoch: 482\n",
      "\tTrain:\tTotal Loss: 1.1423, Feature Loss: 1.1423,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9845, Feature Loss: 0.9845, , LR: 0.000500\n",
      "Epoch: 483\n",
      "\tTrain:\tTotal Loss: 1.1421, Feature Loss: 1.1421,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9856, Feature Loss: 0.9856, , LR: 0.000500\n",
      "Epoch: 484\n",
      "\tTrain:\tTotal Loss: 1.1417, Feature Loss: 1.1417,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9843, Feature Loss: 0.9843, , LR: 0.000500\n",
      "Epoch: 485\n",
      "\tTrain:\tTotal Loss: 1.1419, Feature Loss: 1.1419,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9835, Feature Loss: 0.9835, , LR: 0.000500\n",
      "Epoch: 486\n",
      "\tTrain:\tTotal Loss: 1.1412, Feature Loss: 1.1412,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9838, Feature Loss: 0.9838, , LR: 0.000500\n",
      "Epoch: 487\n",
      "\tTrain:\tTotal Loss: 1.1415, Feature Loss: 1.1415,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9854, Feature Loss: 0.9854, , LR: 0.000500\n",
      "Epoch: 488\n",
      "\tTrain:\tTotal Loss: 1.1411, Feature Loss: 1.1411,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9839, Feature Loss: 0.9839, , LR: 0.000500\n",
      "Epoch: 489\n",
      "\tTrain:\tTotal Loss: 1.1405, Feature Loss: 1.1405,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9833, Feature Loss: 0.9833, , LR: 0.000500\n",
      "Epoch: 490\n",
      "\tTrain:\tTotal Loss: 1.1403, Feature Loss: 1.1403,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9838, Feature Loss: 0.9838, , LR: 0.000500\n",
      "Epoch: 491\n",
      "\tTrain:\tTotal Loss: 1.1403, Feature Loss: 1.1403,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9832, Feature Loss: 0.9832, , LR: 0.000500\n",
      "Epoch: 492\n",
      "\tTrain:\tTotal Loss: 1.1402, Feature Loss: 1.1402,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9831, Feature Loss: 0.9831, , LR: 0.000500\n",
      "Epoch: 493\n",
      "\tTrain:\tTotal Loss: 1.1398, Feature Loss: 1.1398,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9837, Feature Loss: 0.9837, , LR: 0.000500\n",
      "Epoch: 494\n",
      "\tTrain:\tTotal Loss: 1.1397, Feature Loss: 1.1397,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9834, Feature Loss: 0.9834, , LR: 0.000500\n",
      "Epoch: 495\n",
      "\tTrain:\tTotal Loss: 1.1394, Feature Loss: 1.1394,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9838, Feature Loss: 0.9838, , LR: 0.000500\n",
      "Epoch: 496\n",
      "\tTrain:\tTotal Loss: 1.1389, Feature Loss: 1.1389,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9818, Feature Loss: 0.9818, , LR: 0.000500\n",
      "Epoch: 497\n",
      "\tTrain:\tTotal Loss: 1.1390, Feature Loss: 1.1390,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9825, Feature Loss: 0.9825, , LR: 0.000500\n",
      "Epoch: 498\n",
      "\tTrain:\tTotal Loss: 1.1387, Feature Loss: 1.1387,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9831, Feature Loss: 0.9831, , LR: 0.000500\n",
      "Epoch: 499\n",
      "\tTrain:\tTotal Loss: 1.1384, Feature Loss: 1.1384,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9820, Feature Loss: 0.9820, , LR: 0.000500\n",
      "Epoch: 500\n",
      "\tTrain:\tTotal Loss: 1.1383, Feature Loss: 1.1383,  LR: 0.000500\n",
      "\tTest: \tTotal Loss: 0.9831, Feature Loss: 0.9831, , LR: 0.000500\n"
     ]
    }
   ],
   "source": [
    "train_total_losses = []\n",
    "train_feature_losses = []\n",
    "train_edge_losses = []\n",
    "train_kl_losses = []\n",
    "\n",
    "test_total_losses = []\n",
    "test_feature_losses = []\n",
    "test_edge_losses = []\n",
    "test_kl_losses = []\n",
    "\n",
    "if model_loaded:        \n",
    "    print(\"Pretrained Model Loaded, no training required\")\n",
    "else:\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        \n",
    "        train_total_loss, train_feature_loss, train_edge_loss, train_kl_loss = train()\n",
    "        test_total_loss, test_feature_loss, test_edge_loss, test_kl_loss = test()\n",
    "        \n",
    "        print(f\"Epoch: {epoch:03d}\")\n",
    "        print(f'\\tTrain:\\tTotal Loss: {train_total_loss:.4f}, Feature Loss: {train_feature_loss:.4f},  LR: {scheduler.get_last_lr()[0]:.6f}')\n",
    "        print(f'\\tTest: \\tTotal Loss: {test_total_loss:.4f}, Feature Loss: {test_feature_loss:.4f}, , LR: {scheduler.get_last_lr()[0]:.6f}')\n",
    "        \n",
    "\n",
    "\n",
    "        train_total_losses.append(train_total_loss)\n",
    "        train_feature_losses.append(train_feature_loss)\n",
    "        train_edge_losses.append(train_edge_loss)\n",
    "        train_kl_losses.append(train_kl_loss)\n",
    "\n",
    "        test_total_losses.append(test_total_loss)\n",
    "        test_feature_losses.append(test_feature_loss)\n",
    "        test_edge_losses.append(test_edge_loss)\n",
    "        test_kl_losses.append(test_kl_loss)\n",
    "        \n",
    "        scheduler.step()\n",
    "    torch.save(model,\"./models/\"+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if not model_loaded:\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.plot(test_total_losses, label='Total Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Total Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABGwAAAHDCAYAAABxgozAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLSklEQVR4nO3deZhU5Z33/885tfdS3Q00NEuDrWJwJbghQU2MBCRqNDoxLjNREnWMqHF0kuAVRYka1IyJj7uJvwEnbjF5HjTjRCODEeKGorihIigIyr703rWe+/dHLd1FdyNIdZ/T9Pt1XXVRferUOd+q7tNQH773fVvGGCMAAAAAAAB4hu12AQAAAAAAAChEYAMAAAAAAOAxBDYAAAAAAAAeQ2ADAAAAAADgMQQ2AAAAAAAAHkNgAwAAAAAA4DEENgAAAAAAAB5DYAMAAAAAAOAxBDYAAAAAAAAeQ2ADAAAAAADgMQQ2AADgS5k7d64sy+ryNmPGjB4558svv6wbbrhB9fX1PXL8PZF7P5YsWeJ2KQAAYC/gd7sAAADQt/3yl79UXV1dwbZDDjmkR8718ssva9asWbrgggtUWVnZI+cAAADwAgIbAACwR6ZOnaojjzzS7TL2SEtLi0pLS90uAwAAII8hUQAAoEc988wzOu6441RaWqry8nKdfPLJWrZsWcE+77zzji644ALtu+++CofDqqmp0Q9/+ENt3bo1v88NN9ygn/70p5Kkurq6/PCr1atXa/Xq1bIsS3Pnzu10fsuydMMNNxQcx7Isvf/++zr33HNVVVWlY489Nv/4ww8/rCOOOEKRSEQDBgzQ2WefrbVr1xbt/Vi6dKmmTp2qaDSqsrIynXjiiXr11VcL9kkmk5o1a5ZGjx6tcDisgQMH6thjj9X8+fPz+2zYsEHTpk3TiBEjFAqFNHToUJ122mlavXp10WoFAADuocMGAADskYaGBm3ZsqVg26BBgyRJf/jDH3T++edrypQpuvXWW9Xa2qr77rtPxx57rJYuXap99tlHkjR//nx98sknmjZtmmpqarRs2TL97ne/07Jly/Tqq6/KsiydccYZ+uijj/TYY4/pt7/9bf4c1dXV2rx5827X/b3vfU+jR4/Wr371KxljJEk333yzrrvuOp111lm68MILtXnzZt111106/vjjtXTp0j0ehrVs2TIdd9xxikaj+tnPfqZAIKAHHnhA3/jGN7Rw4UKNHz9eUiZUmj17ti688EIdffTRamxs1JIlS/Tmm2/qW9/6liTpzDPP1LJly3T55Zdrn3320aZNmzR//nytWbMm/74CAIA+zAAAAHwJc+bMMZK6vBljTFNTk6msrDQXXXRRwfM2bNhgKioqCra3trZ2Ov5jjz1mJJlFixblt/361782ksyqVasK9l21apWRZObMmdPpOJLM9ddfn//6+uuvN5LMOeecU7Df6tWrjc/nMzfffHPB9nfffdf4/f5O27t7P15//fVu9zn99NNNMBg0H3/8cX7bunXrTHl5uTn++OPz28aOHWtOPvnkbo+zfft2I8n8+te/3mlNAACg72JIFAAA2CP33HOP5s+fX3CTMl0z9fX1Ouecc7Rly5b8zefzafz48fr73/+eP0YkEsnfj8Vi2rJli4455hhJ0ptvvtkjdV9yySUFX/+///f/5DiOzjrrrIJ6a2pqNHr06IJ6v4x0Oq3nnntOp59+uvbdd9/89qFDh+rcc8/Viy++qMbGRklSZWWlli1bphUrVnR5rEgkomAwqBdeeEHbt2/fo7oAAIA3MSQKAADskaOPPrrLSYdzYcM3v/nNLp8XjUbz97dt26ZZs2bp8ccf16ZNmwr2a2hoKGK17XZc2WrFihUyxmj06NFd7h8IBPbofJs3b1Zra6u+8pWvdHrswAMPlOM4Wrt2rQ4++GD98pe/1GmnnaYDDjhAhxxyiE466ST9y7/8iw477DBJUigU0q233qqrr75aQ4YM0THHHKNTTjlFP/jBD1RTU7NHdQIAAG8gsAEAAD3CcRxJmXlsugoR/P72f4acddZZevnll/XTn/5UX/3qV1VWVibHcXTSSSflj7MzlmV1uT2dTnf7nI5dPbl6LcvSM888I5/P12n/srKyL6yjWI4//nh9/PHHeuqpp/Tcc8/pwQcf1G9/+1vdf//9uvDCCyVJV155pU499VQ9+eST+tvf/qbrrrtOs2fP1vPPP69x48b1Wq0AAKBnENgAAIAesd9++0mSBg8erEmTJnW73/bt27VgwQLNmjVLM2fOzG/vajhQd8FMVVWVJKm+vr5g+6effrpb9RpjVFdXpwMOOGCXn7erqqurVVJSouXLl3d67MMPP5Rt26qtrc1vGzBggKZNm6Zp06apublZxx9/vG644YZ8YJOr+eqrr9bVV1+tFStW6Ktf/apuv/12Pfzww0WvHwAA9C7msAEAAD1iypQpikaj+tWvfqVkMtnp8dzKTrluFpNdqSnnjjvu6PSc0tJSSZ2DmWg0qkGDBmnRokUF2++9995drveMM86Qz+fTrFmzOtVijClYYvzL8Pl8mjx5sp566qmCpbc3btyoRx99VMcee2x+mNiO5yorK9P++++veDwuSWptbVUsFivYZ7/99lN5eXl+HwAA0LfRYQMAAHpENBrVfffdp3/5l3/R4YcfrrPPPlvV1dVas2aN/ud//kcTJ07U3XffrWg0quOPP1633Xabksmkhg8frueee06rVq3qdMwjjjhCkvSLX/xCZ599tgKBgE499VSVlpbqwgsv1C233KILL7xQRx55pBYtWqSPPvpol+vdb7/9dNNNN+maa67R6tWrdfrpp6u8vFyrVq3SvHnzdPHFF+vf//3fv/A4//mf/6lnn3220/af/OQnuummmzR//nwde+yxuvTSS+X3+/XAAw8oHo/rtttuy+970EEH6Rvf+IaOOOIIDRgwQEuWLNGf//xnXXbZZZKkjz76SCeeeKLOOussHXTQQfL7/Zo3b542btyos88+e5dfMwAA8C4CGwAA0GPOPfdcDRs2TLfccot+/etfKx6Pa/jw4TruuOM0bdq0/H6PPvqoLr/8ct1zzz0yxmjy5Ml65plnNGzYsILjHXXUUbrxxht1//3369lnn5XjOFq1apVKS0s1c+ZMbd68WX/+85/1xBNPaOrUqXrmmWc0ePDgXa53xowZOuCAA/Tb3/5Ws2bNkiTV1tZq8uTJ+s53vrNLx7jvvvu63H7BBRfo4IMP1j/+8Q9dc801mj17thzH0fjx4/Xwww9r/Pjx+X2vuOIK/eUvf9Fzzz2neDyuUaNG6aabbtJPf/rTfE3nnHOOFixYoD/84Q/y+/0aM2aMnnjiCZ155pm7/HoBAIB3WWbHnl8AAAAAAAC4ijlsAAAAAAAAPIbABgAAAAAAwGMIbAAAAAAAADyGwAYAAAAAAMBjCGwAAAAAAAA8hsAGAAAAAADAY/xuF7Ajx3G0bt06lZeXy7Ist8sBAAAAAAAoCmOMmpqaNGzYMNn2zntoPBfYrFu3TrW1tW6XAQAAAAAA0CPWrl2rESNG7HQfzwU25eXlkjLFR6NRl6sBAAAAAAAojsbGRtXW1uazj53xXGCTGwYVjUYJbAAAAAAAwF5nV6aAYdJhAAAAAAAAjyGwAQAAAAAA8BgCGwAAAAAAAI/x3Bw2AAAAAAD0Bel0Wslk0u0y4DHBYPALl+zeFQQ2AAAAAADsBmOMNmzYoPr6erdLgQfZtq26ujoFg8E9Og6BDQAAAAAAuyEX1gwePFglJSW7tOIP+gfHcbRu3TqtX79eI0eO3KOfDQIbAAAAAAB2UTqdzoc1AwcOdLsceFB1dbXWrVunVCqlQCDwpY/DpMMAAAAAAOyi3Jw1JSUlLlcCr8oNhUqn03t0HAIbAAAAAAB2E8Og0J1i/WwQ2AAAAAAAAHgMgQ0AAAAAAIDHENgAAAAAANAPXHDBBbIsq9Nt5cqVRTn+3LlzVVlZWZRjfVkXXHCBTj/9dFdrKBZWiQIAAAAAoJ846aSTNGfOnIJt1dXVLlXTvWQyuUcrLO0N6LDpAQ1tSb388RYtXbPd7VIAAAAAAMgLhUKqqakpuPl8PknSU089pcMPP1zhcFj77ruvZs2apVQqlX/ub37zGx166KEqLS1VbW2tLr30UjU3N0uSXnjhBU2bNk0NDQ35zp0bbrhBUmYS3ieffLKgjsrKSs2dO1eStHr1almWpT/+8Y/6+te/rnA4rEceeUSS9OCDD+rAAw9UOBzWmDFjdO+99+7R61+4cKGOPvpohUIhDR06VDNmzCh4jX/+85916KGHKhKJaODAgZo0aZJaWlryr/Hoo49WaWmpKisrNXHiRH366ad7VM/O0GHTA554fa1u/usH+vahNbr3vCPcLgcAAAAA0IOMMWpL7tkSzl9GJOAr2opE//jHP/SDH/xAd955p4477jh9/PHHuvjiiyVJ119/vSTJtm3deeedqqur0yeffKJLL71UP/vZz3Tvvffqa1/7mu644w7NnDlTy5cvlySVlZXtVg0zZszQ7bffrnHjxuVDm5kzZ+ruu+/WuHHjtHTpUl100UUqLS3V+eefv9uv8fPPP9e3v/1tXXDBBfqv//ovffjhh7rooosUDod1ww03aP369TrnnHN022236bvf/a6ampr0j3/8Q8YYpVIpnX766brooov02GOPKZFI6LXXXuvR1cIIbHrAQcOikqT31zW6XAkAAAAAoKe1JdM6aObfev287/9yikqCu/ex/umnny4IUqZOnao//elPmjVrlmbMmJEPQvbdd1/deOON+tnPfpYPbK688sr88/bZZx/ddNNNuuSSS3TvvfcqGAyqoqJClmWppqbmS72eK6+8UmeccUb+6+uvv1633357fltdXZ3ef/99PfDAA18qsLn33ntVW1uru+++W5ZlacyYMVq3bp1+/vOfa+bMmVq/fr1SqZTOOOMMjRo1SpJ06KGHSpK2bdumhoYGnXLKKdpvv/0kSQceeOCXep27isCmBxw4NBPYrN7aquZ4SmUh3mYAAAAAgPtOOOEE3XffffmvS0tLJUlvv/22XnrpJd188835x9LptGKxmFpbW1VSUqL//d//1ezZs/Xhhx+qsbFRqVSq4PE9deSRR+bvt7S06OOPP9aPfvQjXXTRRfntqVRKFRUVX+r4H3zwgSZMmFDQFTNx4kQ1Nzfrs88+09ixY3XiiSfq0EMP1ZQpUzR58mT90z/9k6qqqjRgwABdcMEFmjJlir71rW9p0qRJOuusszR06NAv/4K/AElCDxhQGtTQirDWN8T04fpGHbnPALdLAgAAAAD0kEjAp/d/OcWV8+6u0tJS7b///p22Nzc3a9asWQUdLjnhcFirV6/WKaecoh//+Me6+eabNWDAAL344ov60Y9+pEQisdPAxrIsGWMKtiWTyS5r61iPJP3+97/X+PHjC/bLzblTbD6fT/Pnz9fLL7+s5557TnfddZd+8YtfaPHixaqrq9OcOXN0xRVX6Nlnn9Uf//hHXXvttZo/f76OOeaYHqmHwKaHHDQ0qvUNMb1PYAMAAAAAezXLsnZ7aJLXHH744Vq+fHmXYY4kvfHGG3IcR7fffrtsO7N+0RNPPFGwTzAYVDrdeS6f6upqrV+/Pv/1ihUr1NrautN6hgwZomHDhumTTz7Reeedt7svp0sHHnig/u///b8yxuS7bF566SWVl5drxIgRkjLfy4kTJ2rixImaOXOmRo0apXnz5umqq66SJI0bN07jxo3TNddcowkTJujRRx8lsOlrDhoW1YIPNzGPDQAAAADA82bOnKlTTjlFI0eO1D/90z/Jtm29/fbbeu+993TTTTdp//33VzKZ1F133aVTTz1VL730ku6///6CY+yzzz5qbm7WggULNHbsWJWUlKikpETf/OY3dffdd2vChAlKp9P6+c9/vktLds+aNUtXXHGFKioqdNJJJykej2vJkiXavn17PkDpSkNDg956662CbQMHDtSll16qO+64Q5dffrkuu+wyLV++XNdff72uuuoq2batxYsXa8GCBZo8ebIGDx6sxYsXa/PmzTrwwAO1atUq/e53v9N3vvMdDRs2TMuXL9eKFSv0gx/84Eu937uCZb17yEHZeWzeX09gAwAAAADwtilTpujpp5/Wc889p6OOOkrHHHOMfvvb3+Yn3x07dqx+85vf6NZbb9UhhxyiRx55RLNnzy44xte+9jVdcskl+v73v6/q6mrddtttkqTbb79dtbW1Ou6443Tuuefq3//933dpzpsLL7xQDz74oObMmaNDDz1UX//61zV37lzV1dXt9HkvvPBCvhMmd5s1a5aGDx+uv/71r3rttdc0duxYXXLJJfrRj36ka6+9VpIUjUa1aNEiffvb39YBBxyga6+9VrfffrumTp2qkpISffjhhzrzzDN1wAEH6OKLL9b06dP1r//6r1/m7d4lltlxIJnLGhsbVVFRoYaGBkWjUbfL+dJWb2nRN/7jBQX9tt6fNUV+H9kYAAAAAPR1sVhMq1atUl1dncLhsNvlwIN29jOyO5kHKUIPGTmgRKVBnxIpR59saXG7HAAAAAAA0IcQ2PQQ27byy3t/wLAoAAAAAACwGwhsetBBw7Lz2DDxMAAAAAAA2A0ENj1oTE0msPloY5PLlQAAAAAAgL6EwKYH1Q6ISJI+r29zuRIAAAAAANCXENj0oGGV2cBme5s8thgXAAAAAGAPOI7jdgnwqGJ9/vcX5Sjo0vBsYNOSSKuxLaWKkoDLFQEAAAAA9kQwGJRt21q3bp2qq6sVDAZlWZbbZcEjjDHavHmzLMtSILBnGQCBTQ8KB3waWBrU1paEPq9vI7ABAAAAgD7Otm3V1dVp/fr1WrdundvlwIMsy9KIESPk8/n26DgENj1seFUkH9jkVo0CAAAAAPRdwWBQI0eOVCqVUjqddrsceEwgENjjsEYisOlxwyoieuezBq1j4mEAAAAA2Gvkhrzs6bAXoDtMOtzDhlexUhQAAAAAANg9BDY9rONKUQAAAAAAALuCwKaH5VaKosMGAAAAAADsKgKbHkZgAwAAAAAAdheBTQ/LzWGzuSmueIrZwwEAAAAAwBcjsOlhVSUBhQOZt3l9fczlagAAAAAAQF9AYNPDLMvKD4tiaW8AAAAAALArCGx6wfCqEknSZwQ2AAAAAABgF+x2YLNo0SKdeuqpGjZsmCzL0pNPPlnwuDFGM2fO1NChQxWJRDRp0iStWLGiWPX2ScMrw5JY2hsAAAAAAOya3Q5sWlpaNHbsWN1zzz1dPn7bbbfpzjvv1P3336/FixertLRUU6ZMUSzWf+dvYaUoAAAAAACwO/y7+4SpU6dq6tSpXT5mjNEdd9yha6+9Vqeddpok6b/+6780ZMgQPfnkkzr77LP3rNo+qro8JEna2hx3uRIAAAAAANAXFHUOm1WrVmnDhg2aNGlSfltFRYXGjx+vV155pZin6lMqS4KSpPq2pMuVAAAAAACAvmC3O2x2ZsOGDZKkIUOGFGwfMmRI/rEdxeNxxePtnSeNjY3FLMkTKiMBSVJ9K4ENAAAAAAD4Yq6vEjV79mxVVFTkb7W1tW6XVHRVpdkOm9aEy5UAAAAAAIC+oKiBTU1NjSRp48aNBds3btyYf2xH11xzjRoaGvK3tWvXFrMkT6gsyXTYNLQl5TjG5WoAAAAAAIDXFTWwqaurU01NjRYsWJDf1tjYqMWLF2vChAldPicUCikajRbc9jaVkUyHjWOkxhjDogAAAAAAwM7t9hw2zc3NWrlyZf7rVatW6a233tKAAQM0cuRIXXnllbrppps0evRo1dXV6brrrtOwYcN0+umnF7PuPiXot1Ua9KklkVZ9azI/CTEAAAAAAEBXdjuwWbJkiU444YT811dddZUk6fzzz9fcuXP1s5/9TC0tLbr44otVX1+vY489Vs8++6zC4XDxqu6DKkuCakm0aXtrQvuo1O1yAAAAAACAh1nGGE9NqtLY2KiKigo1NDTsVcOjTr7zH1q2rlFzph2lE74y2O1yAAAAAABAL9udzMP1VaL6i6oSVooCAAAAAAC7hsCml1RkV4ra3sKkwwAAAAAAYOcIbHpJVTawqW8jsAEAAAAAADtHYNNLckt7MyQKAAAAAAB8EQKbXlKZGxLVSocNAAAAAADYOQKbXsKkwwAAAAAAYFcR2PSSXIdNPR02AAAAAADgCxDY9JLKXIdNGx02AAAAAABg5whsekm+w4ZlvQEAAAAAwBcgsOkluTlsmuIpJdOOy9UAAAAAAAAvI7DpJRWRQP5+QxtdNgAAAAAAoHsENr3EZ1uKhv2SWCkKAAAAAADsHIFNL6oqzS3tTYcNAAAAAADoHoFNL6rMDovaTmADAAAAAAB2gsCmF+WW9t7OkCgAAAAAALATBDa9qCq7tHcDHTYAAAAAAGAnCGx6ER02AAAAAABgVxDY9KLKEuawAQAAAAAAX4zAphdFw5nApjFGYAMAAAAAALpHYNOLSkM+SVJbIu1yJQAAAAAAwMsIbHpRSdAvSWpNpFyuBAAAAAAAeBmBTS/Kddi00mEDAAAAAAB2gsCmF0UCmQ6bljgdNgAAAAAAoHsENr2IDhsAAAAAALArCGx6UW4OGzpsAAAAAADAzhDY9KL8KlFJOmwAAAAAAED3CGx6UUl2Dptk2iiRclyuBgAAAAAAeBWBTS+KBH35+yztDQAAAAAAukNg04uCfltBX+Ytb2HiYQAAAAAA0A0Cm15WkpvHhg4bAAAAAADQDQKbXlaaXymKDhsAAAAAANA1AptelpvHpoUOGwAAAAAA0A0Cm15Wmg1sWumwAQAAAAAA3SCw6WUl2SFRrUkCGwAAAAAA0DUCm15WGsp12DAkCgAAAAAAdI3AppflOmxY1hsAAAAAAHSHwKaXlQTpsAEAAAAAADtHYNPL6LABAAAAAABfhMCml+XmsGljWW8AAAAAANANApteRocNAAAAAAD4IgQ2vSw/hw0dNgAAAAAAoBsENr0sF9i0xOmwAQAAAAAAXSOw6WWlocyQqDaGRAEAAAAAgG4Q2PSyfIcNQ6IAAAAAAEA3CGx6Wa7DppUOGwAAAAAA0A0Cm14WCeTmsKHDBgAAAAAAdI3Appcxhw0AAAAAAPgiBDa9rLTDHDbGGJerAQAAAAAAXkRg08tKsh02jpHiKcflagAAAAAAgBcR2PSy3Bw2EvPYAAAAAACArhHY9DKfbSkcyLztrBQFAAAAAAC6QmDjgtIgS3sDAAAAAIDuEdi4oCTUPvEwAAAAAADAjghsXJDvsInTYQMAAAAAADojsHFBJEiHDQAAAAAA6B6BjQtyHTZtzGEDAAAAAAC6QGDjghI6bAAAAAAAwE4Q2LigNMQcNgAAAAAAoHsENi5gDhsAAAAAALAzBDYuKM0GNsxhAwAAAAAAulL0wCadTuu6665TXV2dIpGI9ttvP914440yxhT7VH1WSXbSYTpsAAAAAABAV/zFPuCtt96q++67Tw899JAOPvhgLVmyRNOmTVNFRYWuuOKKYp+uT8pNOswcNgAAAAAAoCtFD2xefvllnXbaaTr55JMlSfvss48ee+wxvfbaa8U+VZ8VDmQCm1iKwAYAAAAAAHRW9CFRX/va17RgwQJ99NFHkqS3335bL774oqZOnVrsU/VZkVxgk3RcrgQAAAAAAHhR0TtsZsyYocbGRo0ZM0Y+n0/pdFo333yzzjvvvC73j8fjisfj+a8bGxuLXZLnhAKZnIxJhwEAAAAAQFeK3mHzxBNP6JFHHtGjjz6qN998Uw899JD+4z/+Qw899FCX+8+ePVsVFRX5W21tbbFL8pwIQ6IAAAAAAMBOWKbIyzfV1tZqxowZmj59en7bTTfdpIcfflgffvhhp/276rCpra1VQ0ODotFoMUvzjEUfbdYP/vM1jakp17NXHu92OQAAAAAAoBc0NjaqoqJilzKPog+Jam1tlW0XNu74fD45TtfztYRCIYVCoWKX4WmR7CpR8RRz2AAAAAAAgM6KHticeuqpuvnmmzVy5EgdfPDBWrp0qX7zm9/ohz/8YbFP1WeF/ZnAhjlsAAAAAABAV4oe2Nx111267rrrdOmll2rTpk0aNmyY/vVf/1UzZ84s9qn6rEgw04HEHDYAAAAAAKArRQ9sysvLdccdd+iOO+4o9qH3GiE6bAAAAAAAwE4UfZUofLGOc9g4TlHnfAYAAAAAAHsBAhsX5Jb1lph4GAAAAAAAdEZg44Jwh8AmlmRYFAAAAAAAKERg4wKfbSnoy7z1bQQ2AAAAAABgBwQ2LgkFsitFEdgAAAAAAIAdENi4JDePDR02AAAAAABgRwQ2LsnNYxNLMukwAAAAAAAoRGDjkkg+sKHDBgAAAAAAFCKwcUmYOWwAAAAAAEA3CGxcEmYOGwAAAAAA0A0CG5cwhw0AAAAAAOgOgY1LWCUKAAAAAAB0h8DGJbk5bOIENgAAAAAAYAcENi6JBLMdNgkCGwAAAAAAUIjAxiUhf3YOmxSBDQAAAAAAKERg45L2DhsmHQYAAAAAAIUIbFwSpsMGAAAAAAB0g8DGJZFg5q2PMYcNAAAAAADYAYGNS8Is6w0AAAAAALpBYOOSXGATI7ABAAAAAAA7ILBxCR02AAAAAACgOwQ2LonkO2xYJQoAAAAAABQisHFJOJCddJgOGwAAAAAAsAMCG5dEmMMGAAAAAAB0g8DGJcxhAwAAAAAAukNg45Iwc9gAAAAAAIBuENi4JDeHDR02AAAAAABgRwQ2LsnNYZNIOXIc43I1AAAAAADASwhsXJIbEiVJsRRdNgAAAAAAoB2BjUsKAhvmsQEAAAAAAB0Q2LjEZ1sK+pjHBgAAAAAAdEZg46LcxMMxAhsAAAAAANABgY2LIsHMsKi2BIENAAAAAABoR2Djotw8NnEmHQYAAAAAAB0Q2Lgot7R3W4JJhwEAAAAAQDsCGxeFsoENc9gAAAAAAICOCGxcFAmwShQAAAAAAOiMwMZFYTpsAAAAAABAFwhsXBQhsAEAAAAAAF0gsHFRe4cNkw4DAAAAAIB2BDYuygU2zGEDAAAAAAA6IrBxUTg76TBDogAAAAAAQEcENi6K0GEDAAAAAAC6QGDjIuawAQAAAAAAXSGwcVFuSFScDhsAAAAAANABgY2LQv5Mh008RYcNAAAAAABoR2DjIiYdBgAAAAAAXSGwcREdNgAAAAAAoCsENi6iwwYAAAAAAHSFwMZFdNgAAAAAAICuENi4KESHDQAAAAAA6AKBjYtyHTaxFIENAAAAAABoR2DjotwcNvEkQ6IAAAAAAEA7AhsX5TtsGBIFAAAAAAA6ILBxUb7DhkmHAQAAAABABwQ2LgoH2leJMsa4XA0AAAAAAPAKAhsXhfztbz9dNgAAAAAAIIfAxkW5DhuJiYcBAAAAAEA7AhsX+W1LtpW5H2dpbwAAAAAAkEVg4yLLsvJdNjE6bAAAAAAAQFaPBDaff/65/vmf/1kDBw5UJBLRoYceqiVLlvTEqfq83Dw2MTpsAAAAAABAlr/YB9y+fbsmTpyoE044Qc8884yqq6u1YsUKVVVVFftUe4VMh02SOWwAAAAAAEBe0QObW2+9VbW1tZozZ05+W11dXbFPs9egwwYAAAAAAOyo6EOi/vKXv+jII4/U9773PQ0ePFjjxo3T73//+2KfZq+Rm8OGDhsAAAAAAJBT9MDmk08+0X333afRo0frb3/7m3784x/riiuu0EMPPdTl/vF4XI2NjQW3/iSUn3SYDhsAAAAAAJBR9CFRjuPoyCOP1K9+9StJ0rhx4/Tee+/p/vvv1/nnn99p/9mzZ2vWrFnFLqPPyA2JiqfosAEAAAAAABlF77AZOnSoDjrooIJtBx54oNasWdPl/tdcc40aGhryt7Vr1xa7JE8L02EDAAAAAAB2UPQOm4kTJ2r58uUF2z766CONGjWqy/1DoZBCoVCxy+gz6LABAAAAAAA7KnqHzb/927/p1Vdf1a9+9SutXLlSjz76qH73u99p+vTpxT7VXoEOGwAAAAAAsKOiBzZHHXWU5s2bp8cee0yHHHKIbrzxRt1xxx0677zzin2qvQIdNgAAAAAAYEdFHxIlSaeccopOOeWUnjj0XiccyAQ2dNgAAAAAAICconfYYPeE/NkhUSkCGwAAAAAAkEFg47Jch008yZAoAAAAAACQQWDjsnC2wyZOhw0AAAAAAMgisHFZiA4bAAAAAACwAwIbl+WX9abDBgAAAAAAZBHYuCy/rDcdNgAAAAAAIIvAxmV02AAAAAAAgB0R2LiMDhsAAAAAALAjAhuXheiwAQAAAAAAOyCwcVmuwyZGhw0AAAAAAMgisHFZbg6bOB02AAAAAAAgi8DGZXTYAAAAAACAHRHYuCzfYZOkwwYAAAAAAGQQ2LisfVlvOmwAAAAAAEAGgY3LckOiEilHxhiXqwEAAAAAAF5AYOOyXIeNJMXpsgEAAAAAACKwcV2uw0aS4kw8DAAAAAAARGDjuoDPls+2JEkxlvYGAAAAAAAisPGE9qW9CWwAAAAAAACBjSfkl/ZmDhsAAAAAACACG0+gwwYAAAAAAHREYOMBdNgAAAAAAICOCGw8gA4bAAAAAADQEYGNB4RyHTYs6w0AAAAAAERg4wnhXIcNy3oDAAAAAAAR2HgCHTYAAAAAAKAjAhsPoMMGAAAAAAB0RGDjAbkOmxgdNgAAAAAAQAQ2npDrsInTYQMAAAAAAERg4wmhQG5ZbzpsAAAAAAAAgY0nhP3ZSYfpsAEAAAAAACKw8YRwbg6bBIENAAAAAAAgsPGESJBJhwEAAAAAQDsCGw/Iddi0JemwAQAAAAAABDaeECGwAQAAAAAAHRDYeEAkmFslisAGAAAAAAAQ2HhCJOCXJLUx6TAAAAAAABCBjSfkJh1uJbABAAAAAAAisPGE3Bw2DIkCAAAAAAASgY0nMOkwAAAAAADoiMDGA3KTDhPYAAAAAAAAicDGE8K5DhvmsAEAAAAAACKw8YTckKh4ypHjGJerAQAAAAAAbiOw8YCSoD9/n2FRAAAAAACAwMYDQv72bwOBDQAAAAAAILDxANu2FA5kJx5mHhsAAAAAAPo9AhuPyM1jE6PDBgAAAACAfo/AxiNygQ1DogAAAAAAAIGNR4SDLO0NAAAAAAAyCGw8gg4bAAAAAACQQ2DjESV02AAAAAAAgCwCG48I02EDAAAAAACyCGw8giFRAAAAAAAgh8DGIyIMiQIAAAAAAFkENh6R67CJ0WEDAAAAAEC/R2DjEcxhAwAAAAAAcghsPCI3JKqVIVEAAAAAAPR7BDYeUcKQKAAAAAAAkEVg4xFMOgwAAAAAAHIIbDyCOWwAAAAAAEBOjwc2t9xyiyzL0pVXXtnTp+rTIvnAxnG5EgAAAAAA4LYeDWxef/11PfDAAzrssMN68jR7hdyQqBhDogAAAAAA6Pd6LLBpbm7Weeedp9///veqqqrqqdPsNSIMiQIAAAAAAFk9FthMnz5dJ598siZNmtRTp9ir5OawaU2kXK4EAAAAAAC4zd8TB3388cf15ptv6vXXX//CfePxuOLxeP7rxsbGnijJ80pyQ6KYwwYAAAAAgH6v6B02a9eu1U9+8hM98sgjCofDX7j/7NmzVVFRkb/V1tYWu6Q+Ib+sN0OiAAAAAADo9yxjjCnmAZ988kl997vflc/ny29Lp9OyLEu2bSsejxc81lWHTW1trRoaGhSNRotZmqet3daq4277uyIBnz648SS3ywEAAAAAAEXW2NioioqKXco8ij4k6sQTT9S7775bsG3atGkaM2aMfv7znxeENZIUCoUUCoWKXUafE+4w6bAxRpZluVwRAAAAAABwS9EDm/Lych1yyCEF20pLSzVw4MBO29EuNyRKkuIpJx/gAAAAAACA/qfHVonC7ol0CGhaE8xjAwAAAABAf9Yjq0Tt6IUXXuiN0/RpPttS0G8rkXKYeBgAAAAAgH6ODhsPyXXZtNFhAwAAAABAv0Zg4yG5wCZGhw0AAAAAAP0agY2H5CYeZkgUAAAAAAD9G4GNh4QZEgUAAAAAAERg4ymRQObbQYcNAAAAAAD9G4GNh+SHRNFhAwAAAABAv0Zg4yGRQGaVdTpsAAAAAADo3whsPIQOGwAAAAAAIBHYeApz2AAAAAAAAInAxlMi2VWiYgQ2AAAAAAD0awQ2HhIJZuawaY6nXK4EAAAAAAC4icDGQ6KRTGDT2EZgAwAAAABAf0Zg4yEVkYAkqTGWdLkSAAAAAADgJgIbD4mGs4FNG4ENAAAAAAD9GYGNh+Q6bBoIbAAAAAAA6NcIbDwkmg1smmLMYQMAAAAAQH9GYOMhdNgAAAAAAACJwMZTouH2Zb1TacflagAAAAAAgFsIbDwkNyRKyoQ2AAAAAACgfyKw8ZCAz1ZJ0CeJYVEAAAAAAPRnBDYe0760Nx02AAAAAAD0VwQ2HsPEwwAAAAAAgMDGY6KRzMTDjTECGwAAAAAA+isCG49pHxJFYAMAAAAAQH9FYOMxDIkCAAAAAAAENh6TW9qbIVEAAAAAAPRfBDYeE6XDBgAAAACAfo/AxmOi4eykwyzrDQAAAABAv0Vg4zEVDIkCAAAAAKDfI7DxGIZEAQAAAAAAAhuPYVlvAAAAAABAYOMx7ct6M4cNAAAAAAD9FYGNx0Qj2UmHmcMGAAAAAIB+i8DGY3IdNomUo1gy7XI1AAAAAADADQQ2HlMa9Mu2MveZxwYAAAAAgP6JwMZjbNtSeZilvQEAAAAA6M8IbDyogqW9AQAAAADo1whsPCg/8TArRQEAAAAA0C8R2HhQrsOGIVEAAAAAAPRPBDYeFA0zJAoAAAAAgP6MwMaD8h02BDYAAAAAAPRLBDYeVFUalCRtboq7XAkAAAAAAHADgY0HjaiKSJI+r29zuRIAAAAAAOAGAhsPGl6ZCWw+205gAwAAAABAf0Rg40EjqkokSZ9vb5MxxuVqAAAAAABAbyOw8aBch01TPKXGtpTL1QAAAAAAgN5GYONBkaBPA7MTD39W3+pyNQAAAAAAoLcR2HhUbuJh5rEBAAAAAKD/IbDxqOG5laIIbAAAAAAA6HcIbDwqP/EwS3sDAAAAANDvENh4VPvS3sxhAwAAAABAf0Ng41G5OWzosAEAAAAAoP8hsPGo4Uw6DAAAAABAv0Vg41G5IVH1rUk1x1MuVwMAAAAAAHoTgY1HlYcDqogEJLFSFAAAAAAA/Q2BjYe1z2PDxMMAAAAAAPQnBDYe1r5SFB02AAAAAAD0JwQ2Hrbf4DJJ0pufbne5EgAAAAAA0JsIbDzsm2MGS5IWfLhJybTjcjUAAAAAAKC3ENh42OEjqzSoLKimWEqvfrLV7XIAAAAAAEAvKXpgM3v2bB111FEqLy/X4MGDdfrpp2v58uXFPk2/4LMtfeugIZKkvy3b4HI1AAAAAACgtxQ9sFm4cKGmT5+uV199VfPnz1cymdTkyZPV0tJS7FP1C5MPrpEkPbdsoxzHuFwNAAAAAADoDf5iH/DZZ58t+Hru3LkaPHiw3njjDR1//PHFPt1e72v7DVRZyK9NTXEtXVuvI0ZVuV0SAAAAAADoYT0+h01DQ4MkacCAAT19qr1SyO/LTz581RNvae221i98jjFGrYmU4qk0XTkAAAAAAPRBljGmxz7RO46j73znO6qvr9eLL77Y5T7xeFzxeDz/dWNjo2pra9XQ0KBoNNpTpfUpn21v1Tm/f1Vrt7VpSDSk0746XEOiYa2vb9On21q1ZmurNjfH5bctSdK2loRSHYIa25L8PlsB28r86bNkW5ZSjpFtWRpQGtDA0pAGlAUVDfvlt235fZYCPlt+25LftlQW9qumIqLysF/pdObYQb/dfvNl/kw7Rq2JtMpCftUOiCjk96k1kZKRFPTZCvltWZblxtsIAAAAAICrGhsbVVFRsUuZR48GNj/+8Y/1zDPP6MUXX9SIESO63OeGG27QrFmzOm0nsCm0oSGmf/7/Fmvlpma3S9ljAZ+VD3hKQ35VRALy+2wp+6PY8QeyIhJQdVlIrYl0NohqX97csiyVhfyqLAmoMhJQNBKQZVkyxsgxRo6RHGNkjPKdRhXZ/dKOUSLtKJlylEhnbqlsEBXw2RpaEVZFJKDPtrdqe2tSlZGAysP+gvqMydzPXUK5Kykc9GmfgSWqKgmqvjWpRDqtgC8TagU6hFu512bbBFgAAAAA0B94IrC57LLL9NRTT2nRokWqq6vrdj86bHZdYyyp/3lnvZZvaNLGxpiGVkQ0amCJRg0sUU1FOB84DCwLKhoOKG2MUmmjVNpR0sn+mTZKOY7SjlHAZyuZdrStJaFtLQltbU6oOZ5SKu0o5RilHKNkOrNvY1tS6xpiak2k5LdtGUmJlKNEKp0JPFKZm8+2FQnaamhNqjGWcvcN6wPCAVvV5SGVBv2KBH0qCfo0tCKiI0ZV6YAhZaqIBDS8skSRoM/tUgEAAAAAe8jVwMYYo8svv1zz5s3TCy+8oNGjR+/W83eneHhbQ2tSKcdRacgvy1I+1MkFPPGUo6ZYSo1tSaWzHTC50VKWJTmOtL01oa0tCZUGfRpQGlLA196N4hijplhKDW1J1bcm1dCWlJRZDt2yJNuyZGf/zHXeNLQl1RhLym/bma4Xf6bbJ+Cz5cseO550tK6+TY2xpIZXlmhQWVANbUk15QIoS7Kk/NAuK1tvbltTLKlVW1rUHE+pMhJUKGDnX3eyQ7jV0JbUrkwxFPBZGldbpXEjK7Xf4DKNHVGpA4aUMbQMAAAAAPqY3ck8ir5K1PTp0/Xoo4/qqaeeUnl5uTZs2CBJqqioUCQSKfbp4GEVJYGCr0N+ukQ6SqYdfb69TVtbEmpLpNWaSKk1kdbKTc1a8uk2rauPaXtrQk2xlF5bvU2vrd6Wf251eUgT9xuoY0dX69j9B6mmIuziKwEAAAAAFFvRO2y6+1//OXPm6IILLvjC59NhA7QzxmjNtla98vFWfbC+UR9tbNZba+vVlkwX7Lf/4DIdu/8gTdx/kI7Zd4DKw4FujggAAAAAcIsn5rD5sghsgJ2Lp9J689N6vbRyi15cuUXvfFZfMLTKZ1v6am2lJu4/SMeNHqSv1lYq4LPdKxgAAAAAIInABuhXGlqTeuWTrXpx5Wa9tHKrVm1pKXi8NOjT+H0H6ptjBmvKwTWqLg+5VCkAAAAA9G8ENkA/9tn21mz3zVa9tHKLtrUk8o/ZlnR03QB9+9ChOungGg2OMvcNAAAAAPQWAhsAkiTHMfpgQ6MWfbRFz763Xm9/1pB/zLKko0YN0FlH1eo7Y4cp6GfYFAAAAAD0JAIbAF1au61Vz763QX99b72WrqnPb6+JhjVt4j46Z/xIRZmwGAAAAAB6BIENgC+0rr5N85Z+rodeXq1NTXFJUnnIr5MPG6pvHzpUE/cfJJ/d9apvAAAAAIDdR2ADYJfFU2k99dY6/W7RJ1q5qTm/fUxNuX5x8oE6bnS1i9UBAAAAwN6DwAbAbnMco1c+2aq/vrte//32OjXGUpKko/ap0sXH76cTxwyWTccNAAAAAHxpBDYA9kh9a0J3LlipP7y6Wsl05lfEwcOiumbqgTp29CCXqwMAAACAvonABkBRbGyMae7Lq/WHVz5VczzTcXPc6EGaMXWMDh5W4XJ1AAAAANC3ENgAKKqtzXHd9fxKPbL403zHzXfHDddV3zpAtQNKXK4OAAAAAPoGAhsAPWLN1lb9x3PL9Ze310mSgj5b047dR5edsL/KWQ4cAAAAAHaKwAZAj3r3swbd8uwHemnlVknSoLKQfjBhlL5/VK2GRMMuVwcAAAAA3kRgA6DHGWP09+WbdOPTH2jVlhZJks+2dPHx++rKSaMV8vtcrhAAAAAAvIXABkCvSaQc/c+76/To4jV6ffV2SdLowWX6j++N1djaSneLAwAAAAAPIbAB4Ipn39uga598V1uaE7It6eLj99P5XxuloRURt0sDAAAAANcR2ABwzfaWhK7/y7L8xMSSdNiICl12wv761kFDZFmWi9UBAAAAgHsIbAC47m/LNuiBhR9r6dp65X7LfG2/gfrlaYdo/8Fl7hYHAAAAAC4gsAHgGZub4prz0io9+OIqJVKOgn5bl5+wv0776nDVDojQcQMAAACg3yCwAeA5a7e16ton39PCjzbntw2vjOiHx9bp3KNHKhJkVSkAAAAAezcCGwCeZIzRvKWf6+FXP9W7nzcomc78+hlYGtR3xw3XmUeM0JiacrpuAAAAAOyVCGwAeF5bIq2n3vpcd/99pT7b3pbfPrQirONGD9Jxo6t13OhBqiwJulglAAAAABQPgQ2APiOZdrRw+Wb96Y21emH5ZsVTTv4xv21p8sFD9L0jajV+3wEqCfpdrBQAAAAA9gyBDYA+KZZM67VV2/SPFZu16KMtWr6xKf9YwGdpTE1UwysjGjWwRGOGluugoRXat7pUAZ/tYtUAAAAAsGsIbADsFT5Y36jHXluj/31/o9Y1xLrcJ+izdfDwqL75lcE6cGhUsVRapSG/DhhSrsHlIaXSRiG/Ldu2lEo7enNNvUqCPh08LMpcOQAAAAB6FYENgL2KMUZrt7Xpgw2NWl/fpk+2tOiD9Y36YH2TmuOpL3x+yG9rv+oyrWtoU31rUpI0pqZcxx9QrcqSgGKJtDY0xlQS9Gvf6lINLA0pErQ1qCyk4ZURxVKONjS0KZk2Cvhs1VZFVF0eUlsyrY82Nivos1VdHlLQbyuRcvTaqm16+7N6HTwsqikH1ygcYAUsAAAAAAQ2APoJxzFau71Vr3y8Vc9/uEkbG2MKBXyqb03ok80tSjmdf71VlQTUkkgr0WGunC+jIhJQUyypLk5RoDzsV92gUpUG/Yqn0mqJp9UcT6ktmZYxJt/lY0nK3M1+bXXcJgX9tkYOKNHIAaUqC/nkmMxS6dtbExoSDasiEtDmpria4ylVlQY1qDSogWWZEGljY0yxpKMh0ZDKQn7VtyaVcowGl4dUFvYrnnIUT6YVS6YVTzmKJdNyTOacAZ+tkN9WwGcp6LMV9Psy9/22gj5baWPUlkgrFPCpJhrW+oY2LV1Tr6Df1qHDK1RZElBbIi3LshTwWYolHTXGkrKyrynk9ykUyJwjlP066LflGKNkyijpOEqljXy2pZDf1pBoWIPKgmpsS+mz+lYl00aOMcr8VWZpYGlQ1eUhWZbkGCntGKXSjurbkmqOpRQO+FQSzNxKQ36F/LYsy1IsmVZrIq3ysF9+21JrIvN9siSFAj5Fw/6ddmQl045M9j0DAAAAukNgA6DfS6QctSXS8vksbW6Ka8XGJkUjAR05qkot8bT++511Wr2lRdtbkwoHbNVEw2pOpLRqc4sa2pJqTaS1sTGmTU1xBXyWairCCvpsxVOO1tW35YOa6vKQjDHa2pJQ7rfp6MFlGjeyUi+t3KrP69u6LxJfit+2ugzjvgzbkvy2rUS6PcAL+Kz8kvM5kYBPlSUBNbYlFU85qogEFPLbak2m1RpP55+fCYP8kowck+kOc4zkGCNl/3SMZDo8Xhbya+SAEvlsS1uaE5KkAaVBhQO2HCOFAz5VRAIK2JaS2QAqVfCnUdoxikYCGloRVlsy87Obdoz8PlsB25LfZyngywRwftvKbPdZ8tu2Uo6jeNJRIu0omXZUVRLUgNKgGtqS2t6aUHVZSMMqI/Jl3/dU2pGRVBbyKxzwaVtLXPWtSfmz4V7QZyscsFUS9Cvot9UUS6k1kZJtZerw2Zb8tiWfbWf/tPJ/ph2jhrZMEDq8KqKqbOCXcjKhnZMNCI2RSkI+lQb9Kg351JpIa822VjlGGlEVUWUkICOpNZ7W9tZEtl6fykIBlYZ8iqccbW1OKOCzVF0eUnkooKDfVlsyrYa2pEqCPg0qC6kpltSaba2KBHyqqQjLtiy1JdNqS6QVT6VVEQlqYGlQliWlHCPbsmRbYrglAADoFoENABRJPJVWwM7MgZMTS6b1yeYWDSoLanA0LCnTyZHOhgi5Lou0Y/Tu5w3a2pzpfAn5fSoLZT5glob8yh3RSDLZD/HK3d/h61gyrVVbWvTZ9rZsB4xR7YASVZUEtbExpsa2pKqzHTPbW5La2hLXtpaEYklHg6MhRQI+bWyMqyWeUlVJQJZlaXNz5uuw36dwINPdEg7YCgd8sixLybSjRCpzS6YdxdPt93PbbdtSJOBTWyKtjU0xVUQCOmJUlZJpR+993qhYMq1I0CdjMiFaOGArGgnIkjKdPSlH8VSm4ynT6ZP52mcXBgwpx6gtmdaW5ng+GBtYGlQ44JNtS7aV+TC/pSmhtmS60/exPOxXeSjTTdSSSCmW/OIOq9y3vEjZEPoY29q1773ftmSk/PWf2+bPBmI+OxPi2JYlKx/oZPazduioy9wvDHusHfb3+ywNKgupMhJQIu3kO+OMyV4TQZ+2NScUS6U1qCykkqBP21uTiiczHWS56ztzvPZz+G1bZSGfUo7Rpqa4bEvaZ2CpbNvS59vb1JZMKxzw5bvhcpO9W9nXFvLbKg8HlEg52t6aCR4jQZ9KAj5Fgj7ZlpX9XZfrilN7mKnMMfIBXv69y9SXzTvzvxdzX0uSb4fn+WxLvuy58gGpyYVpHd//9ve541ve8d3PfV8dY7K/jzK/l3y2JUtWh05IK/8+BH2ZDsHGWFJpx6g05FfAZ+eP4ziZ3+yWJNu28p2UlmXlj2Vbaj9+h/u21fmcljpu7/CcLziOpPzv8kA2ZLUKXn2H98TOvM+2Zcm22/+Oyn3vgn5btmWpJZFSPOmoPNzevZh/L037983p8NEj/1o6vA8AsLcjsAEA7JXiqbQ2N8U1oDTY5TLvxhi1JjKBTeaDcvYDnF34ISCdDYBa4ykl0pmOmZKgX41tSbUl06osCSiS/WAbS6a1viETilVEMp0YjbGk4klHpaFMR01ptpbtrZnAyM5/gJOkjh/Y2z8s5T6s1bcmtXZ7q4wxGlQWkiRtbUkomXZkKdPRUd+akGOM/HbmQ6PPtrNdM5n7PsvS9taE1je0qSTo15BoON8plEo77Z056fZhZrntAdvKD0+zbUvbWxLa1ppQRSSgykhAm5ri2tAQkyzlPxhLUks8pdZEWgNLg6osCSrtmGzwllYsmQnGEilH5eFMV0tmiJqT7whKObk/nfzXtmXlu2M+396mxlhSkaBPATsz/M5SpotJlqW2RCo/xDCUHTJoW5bWbm9VcywlWZnOqAGlwfyHyeZYSs3xlIJ+WwNLg0qmjTY3xQs6rEqDPrVlhwVKmS66WDKtplj7fFm5gLMxlpS3/hUFeEPu90QunNtdBcGU2gMndRgu3DE0s62Oj1ldPl8d9k87Rom0o3DAp6qSgIyRWhNppR1T8Nx8LTsGZ5nDFZxDHevMnzO3vXNI2jGIbb/fvkPHfXOPdXkcte/Q+Tkdjt3Ftm5r6+Kx9ud0FTRLIb9PpSFf/j9QMv+RpS51l8t1tbmrfbsKF23bki8XLmZD1Y7P7/Te7PC61eH96e557QGotUNY2vm4O9a/4/d5V74fXX7vrY41d/+z98U/I+0nTWY7bEN+u2DeRaeLi7fje9/t97HDA1bB9i8+Tnf7q4v9T/jK4D47FJ3ABgAAYBcYY5RMZz685TpHUmlHW1sSKg/788FgayIlS1Z+1Tkp84/cLc3x/HZJnYKozPC69qFxuU6cjv/6yt3v2FWX+VrK/TMtt3si5WhzU1wNbcn8P67DAV9+aGZbIq2BZUGF/D5taY4rlkyrsiSokN9WczylWLYDreM5csdtiadkW1J1NKx02tGn21rlOEbDqyIqDfmzHXCZrp60Y/LdLk62C7AxlqmpqiQzTKwt4agtmQn2HKP24FIdOkCyHyZy700q+97lgj2p/cN27n7HDzL5uaqcTPdK7n3PHT8XkOY6Qjp2hnR8/bmfhR35fbas7Pc115GSznbJGJP9jmWflsqGlrYlRSMB2Zal1kRKybSRXfBBUvnn5TpOOtanDtvah08q/3OUO2+uWyc33DLXheSYrrabTh1j/mwnYyLtFHSIAUBf8NbMb6myJOh2GV/K7mQenf97EgAAoJ+wLEtBv1Xwv3R+X2aC64666ugK+GwNrYj0eI1AMeXCm46dh8kdWiFyj+SHljlSOjucze4QhhkjJdKOUmlHpSG/gj5bLYlMSNfehVLYmZIL6ToObzMdAieTTbK6GgZnOoRaXT3mZJOqLofRdbifG+LWlkxre0tStiWVhDKTznd5TrWHZrmQsnB7e925961jjSrYb4cgtovAdsdANR8Odqij8zG7OE6H56vg+e2vcae1Ze90fczC48Szoa9jTD6c9Nmde2G6iwa7aiEwXezd5X7Z731ueHra7Pj+7PCGqvN70/k971yH6RiYdhjaKXX+udzxmN39nOz4fu/4fev4fcg9v7tzda7ddPu97fj6Aj5bQb+leNLJDyvPdQ91p6v3p9P2Xdmn4KC7t/+O3dN7KwIbAAAAoJ+wLEu+HT7n5OYk+jIi8hV8XR4OqDwc+NLHAwC065uDvgAAAAAAAPZiBDYAAAAAAAAeQ2ADAAAAAADgMQQ2AAAAAAAAHkNgAwAAAAAA4DEENgAAAAAAAB5DYAMAAAAAAOAxBDYAAAAAAAAeQ2ADAAAAAADgMQQ2AAAAAAAAHkNgAwAAAAAA4DEENgAAAAAAAB5DYAMAAAAAAOAxBDYAAAAAAAAe43e7gB0ZYyRJjY2NLlcCAAAAAABQPLmsI5d97IznApumpiZJUm1trcuVAAAAAAAAFF9TU5MqKip2uo9ldiXW6UWO42jdunUqLy+XZVlul/OlNTY2qra2VmvXrlU0GnW7HMB1XBNAZ1wXQGdcF0Ahrgmgs758XRhj1NTUpGHDhsm2dz5Ljec6bGzb1ogRI9wuo2ii0Wif+wECehLXBNAZ1wXQGdcFUIhrAuisr14XX9RZk8OkwwAAAAAAAB5DYAMAAAAAAOAxBDY9JBQK6frrr1coFHK7FMATuCaAzrgugM64LoBCXBNAZ/3luvDcpMMAAAAAAAD9HR02AAAAAAAAHkNgAwAAAAAA4DEENgAAAAAAAB5DYAMAAAAAAOAxBDY94J577tE+++yjcDis8ePH67XXXnO7JKDHLFq0SKeeeqqGDRsmy7L05JNPFjxujNHMmTM1dOhQRSIRTZo0SStWrCjYZ9u2bTrvvPMUjUZVWVmpH/3oR2pubu7FVwEUz+zZs3XUUUepvLxcgwcP1umnn67ly5cX7BOLxTR9+nQNHDhQZWVlOvPMM7Vx48aCfdasWaOTTz5ZJSUlGjx4sH76058qlUr15ksBiua+++7TYYcdpmg0qmg0qgkTJuiZZ57JP841gf7ulltukWVZuvLKK/PbuC7Q39xwww2yLKvgNmbMmPzj/fGaILApsj/+8Y+66qqrdP311+vNN9/U2LFjNWXKFG3atMnt0oAe0dLSorFjx+qee+7p8vHbbrtNd955p+6//34tXrxYpaWlmjJlimKxWH6f8847T8uWLdP8+fP19NNPa9GiRbr44ot76yUARbVw4UJNnz5dr776qubPn69kMqnJkyerpaUlv8+//du/6b//+7/1pz/9SQsXLtS6det0xhln5B9Pp9M6+eSTlUgk9PLLL+uhhx7S3LlzNXPmTDdeErDHRowYoVtuuUVvvPGGlixZom9+85s67bTTtGzZMklcE+jfXn/9dT3wwAM67LDDCrZzXaA/Ovjgg7V+/fr87cUXX8w/1i+vCYOiOvroo8306dPzX6fTaTNs2DAze/ZsF6sCeockM2/evPzXjuOYmpoa8+tf/zq/rb6+3oRCIfPYY48ZY4x5//33jSTz+uuv5/d55plnjGVZ5vPPP++12oGesmnTJiPJLFy40BiTuQYCgYD505/+lN/ngw8+MJLMK6+8Yowx5q9//auxbdts2LAhv899991notGoicfjvfsCgB5SVVVlHnzwQa4J9GtNTU1m9OjRZv78+ebrX/+6+clPfmKM4e8K9E/XX3+9GTt2bJeP9ddrgg6bIkokEnrjjTc0adKk/DbbtjVp0iS98sorLlYGuGPVqlXasGFDwTVRUVGh8ePH56+JV155RZWVlTryyCPz+0yaNEm2bWvx4sW9XjNQbA0NDZKkAQMGSJLeeOMNJZPJgutizJgxGjlyZMF1ceihh2rIkCH5faZMmaLGxsZ8RwLQV6XTaT3++ONqaWnRhAkTuCbQr02fPl0nn3xywc+/xN8V6L9WrFihYcOGad9999V5552nNWvWSOq/14Tf7QL2Jlu2bFE6nS74AZGkIUOG6MMPP3SpKsA9GzZskKQur4ncYxs2bNDgwYMLHvf7/RowYEB+H6CvchxHV155pSZOnKhDDjlEUuZnPhgMqrKysmDfHa+Lrq6b3GNAX/Tuu+9qwoQJisViKisr07x583TQQQfprbfe4ppAv/T444/rzTff1Ouvv97pMf6uQH80fvx4zZ07V1/5yle0fv16zZo1S8cdd5zee++9fntNENgAANBDpk+frvfee69g/DXQX33lK1/RW2+9pYaGBv35z3/W+eefr4ULF7pdFuCKtWvX6ic/+Ynmz5+vcDjsdjmAJ0ydOjV//7DDDtP48eM1atQoPfHEE4pEIi5W5h6GRBXRoEGD5PP5Os1UvXHjRtXU1LhUFeCe3M/9zq6JmpqaTpNyp1Ipbdu2jesGfdpll12mp59+Wn//+981YsSI/PaamholEgnV19cX7L/jddHVdZN7DOiLgsGg9t9/fx1xxBGaPXu2xo4dq//zf/4P1wT6pTfeeEObNm3S4YcfLr/fL7/fr4ULF+rOO++U3+/XkCFDuC7Q71VWVuqAAw7QypUr++3fFQQ2RRQMBnXEEUdowYIF+W2O42jBggWaMGGCi5UB7qirq1NNTU3BNdHY2KjFixfnr4kJEyaovr5eb7zxRn6f559/Xo7jaPz48b1eM7CnjDG67LLLNG/ePD3//POqq6srePyII45QIBAouC6WL1+uNWvWFFwX7777bkGYOX/+fEWjUR100EG980KAHuY4juLxONcE+qUTTzxR7777rt5666387cgjj9R5552Xv891gf6uublZH3/8sYYOHdp//65we9bjvc3jjz9uQqGQmTt3rnn//ffNxRdfbCorKwtmqgb2Jk1NTWbp0qVm6dKlRpL5zW9+Y5YuXWo+/fRTY4wxt9xyi6msrDRPPfWUeeedd8xpp51m6urqTFtbW/4YJ510khk3bpxZvHixefHFF83o0aPNOeec49ZLAvbIj3/8Y1NRUWFeeOEFs379+vyttbU1v88ll1xiRo4caZ5//nmzZMkSM2HCBDNhwoT846lUyhxyyCFm8uTJ5q233jLPPvusqa6uNtdcc40bLwnYYzNmzDALFy40q1atMu+8846ZMWOGsSzLPPfcc8YYrgnAGFOwSpQxXBfof66++mrzwgsvmFWrVpmXXnrJTJo0yQwaNMhs2rTJGNM/rwkCmx5w1113mZEjR5pgMGiOPvpo8+qrr7pdEtBj/v73vxtJnW7nn3++MSaztPd1111nhgwZYkKhkDnxxBPN8uXLC46xdetWc84555iysjITjUbNtGnTTFNTkwuvBthzXV0PksycOXPy+7S1tZlLL73UVFVVmZKSEvPd737XrF+/vuA4q1evNlOnTjWRSMQMGjTIXH311SaZTPbyqwGK44c//KEZNWqUCQaDprq62px44on5sMYYrgnAmM6BDdcF+pvvf//7ZujQoSYYDJrhw4eb73//+2blypX5x/vjNWEZY4w7vT0AAAAAAADoCnPYAAAAAAAAeAyBDQAAAAAAgMcQ2AAAAAAAAHgMgQ0AAAAAAIDHENgAAAAAAAB4DIENAAAAAACAxxDYAAAAAAAAeAyBDQAAAAAAgMcQ2AAAAAAAAHgMgQ0AAAAAAIDHENgAAAAAAAB4DIENAAAAAACAx/z/pHELjo5GEpYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1400x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not model_loaded:\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.plot(test_feature_losses, label='Feature Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Feature Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(graphs, batch_size=1)\n",
    "decoded_data=[]\n",
    "for data in train_loader:\n",
    "    model.eval()\n",
    "    z,encoded_edge_index = model.encode(data.x, data.edge_index)\n",
    "    decoded_data.append(z.detach().numpy())\n",
    "\n",
    "decoded_data = np.array(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame = 4\n",
    "plt.figure(figsize=(14, 5))\n",
    "data = decoded_data[frame]\n",
    "plt.scatter(data[:,0], data[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"para_melt.txt\",\"w\") as f:\n",
    "    for data in decoded_data[frame]:\n",
    "        f.write(str(data[0])+\" \"+str(data[1])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = [1,2,3]\n",
    "l2 = [4,5,6]\n",
    "l1+l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAENN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80a33ba5fbbc6f374c4c23ec54f7c94fc3dd605e2ab2c49345e5901997a9893b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
